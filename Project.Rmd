---
title: "Projet Stats"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center", results="hold")
library(ggplot2)
library(esquisse)
library(FactoMineR)
library(leaps)
library(MASS)
library(glmnet)
library(gridExtra)
```

# Data analysis

## Ababakar : Description

```{r}
# Lecture jeu de données
setwd("/home/leo/GoogleDrive/Cours/INSA_4A/Projet")
data = read.table("DataEnergy-Student.csv", header = TRUE, sep = ",")
data
# Mise sous forme de facteur des données catégorielles
data$Energy.efficiency = as.factor(data$Energy.efficiency)
data$Glazing.area.distr = as.factor(data$Glazing.area.distr)
data$orientation = as.factor(data$orientation)
# Correction du jeu de données
data$Glazing.area[which(data$Glazing.area.distr == 0)] = 0
# Infos sur le jeu de données
str(data)
```
Le jeu de données est composé de 768 batiments avec chacun 10 variables.

Quantitatives :
- Relative.compactness : compacité relative à un cube de même volume (FORMULE)
- Surface.area : surface totale (sol + murs + toit)
- Wall.area : surface de mur extérieurs
- Roof.area : surface de toit
- Overall.height : hauteur du batiment (soit 3.5 soit 7 m)
- Glazing.area : Surface vitrée (en pourcentage de la surface au sol)
- Load : Energie consommée (sortie du problème)
Catégorielles :
- orientation : orientation de la maison (Nord, Sud, Est, Ouest)
- Glazing.area.distr : Distribution des vitres (Uniforme, ou plus d'un coté)
- Energy.efficiency : Indicateur de l'énergie consommées (de A à G)

```{r}
quanti <- c(1:5, 7, 9)
quali <- c(6, 8, 10) 
pairs(data[, quanti], pch = '.', cex = 0.1, cex.labels = 0.55) 
plot(2*data$Roof.area + data$Wall.area, data$Surface.area)
```


```{r}
summary(data)
```

Même nombre de batiments faisant face à chaque orientation. Même nombre de batiments avec les différentes répartitions de fenêtres, sauf les batiments sans fenêtres.

```{r}
ggplot(data) +
 aes(x = Glazing.area, y = Energy, colour = as.factor(Overall.height)) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")
```

On voit que la surface vitrée à une influence sur l'énergie consommée.

```{r}
boxplot(Energy ~ Overall.height, data = data)
```

## Léo : ACP

On souhaite réaliser une ACP afin de mener une analyse en dimension plus faible. Nous allons pour cela utiliser le package \texttt{FactoMineR} qui contient toutes les fonctions nécessaires à la réalisation de notre ACP. On cherche d'abord combien d'axes principaux nous allons avoir besoin.

```{r}
library("FactoMineR")
par(mfrow=c(1,2))
res.acp <- PCA(data,scale.unit=T,quali.sup=c(6,8,10),quanti.sup=9,ncp=8, graph=F)
barplot(res.acp$eig[,"percentage of variance"], main="Pourcentage d'inertie", names.arg = seq(1,6), xlab = "Composantes principales")
barplot(res.acp$eig[,"cumulative percentage of variance"],
        main="Pourcentage d'inertie cumulé",
        names.arg = seq(1,6), xlab = "Composantes principales")
abline(h = 95, col = "red")
print(paste("Pourcentage d'inertie expliquée par les trois premiers axes principaux :",res.acp$eig[,"cumulative percentage of variance"][3]))
```

On voit sur le premier graphe que l'inertie portée par les trois premiers axes principaux est prépondérante par rapport aux autres. D'après le graphe de pourcentage d'inertie cumulée, ils expliquent presque 99\% de l'inertie. Les deux premiers axes ne portent eux que 82\% de l'inertie. Ne choisir que deux axes effacerait trop d'informations. Nous allons donc poursuivre notre analyse sur les trois premiers axes principaux.

Les graphes des variables nous donnent des informations très intéressantes sur les variables corrélées.

```{r, fig.dim=c(2,2)}
gg1 = plot.PCA(res.acp, choix="var", axes = c(1,2), new.plot = FALSE, title = "Graphe des variables (axes 1 et 2)")
gg2 = plot.PCA(res.acp, choix="var", axes = c(1,3), new.plot = FALSE, title = "Graphe des variables (axes 1 et 3)")
gg3 = plot.PCA(res.acp, choix="var", axes = c(2,3), new.plot = FALSE, title = "Graphe des variables (axes 2 et 3)")
grid.arrange(gg1,gg2,gg3,ncol = 2,widths=c(10,10))
```

Les variables `Relative.compactness`, `Overall.height`, `Surface.area` et `Roof.area` semblent être plutôt portées par le premier axe principal (en positif pour les deux premières, négatif pour les deux autres).

Le second axe porte principalement la variable `Wall.area`, et le troisième la variable `Glazing.area`.

Finalement, les deux premiers axes ont plutôt trait à la forme du bâtiment (surface au sol pour le premier et surface murée pour le second), tandis que le troisième axe correspond à la surface vitrée.

Ainsi, l'énergie dépensée dépend d'abord de la forme du bâtiment, et ensuite de la surface vitrée.

Nous pouvons également observer les graphes des individus. Nous représentons les différentes classes énergétiques par couleur.


```{r}
gg1 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="Energy.efficiency", label = "none")
gg2 = plot(res.acp, choix="ind", axes = c(2,3), invisible="quali", habillage="Energy.efficiency", label = "none")
gg3 = plot(res.acp, choix="ind", axes = c(1,3), invisible="quali", habillage="Energy.efficiency", label = "none")
grid.arrange(gg1,gg2,gg3,ncol = 2,widths=c(10,10))
```

On peut voir sur le premier et le troisième graphique que l'axe 1 marque une claire séparation entre les classes A, B, C et les classes D, E, F, G.
Les maisons dont la consommation énergétique la plus faible possèdent des coordonnées négatives pour la première composante. Ces maisons sont celles qui ont une compacité relative plus faible (plus basses et avec une surface au sol plus élevée), comme on peut le voir sur les graphiques suivants :

```{r}
gg1 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="Relative.compactness", label = "none")
gg2 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="Surface.area", label = "none")
gg3 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="Overall.height", label = "none")
grid.arrange(gg1,gg2,gg3,ncol = 2,widths=c(10,10))
```

Ainsi, les maisons plus étalées sur le sol possèdent les meilleures performances énergétiques.


## Quentin : clustering
### Analyse visuelle

```{r}
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = "#0c4c8a") +
 theme_minimal()
ggplot(data) +
 aes(x = Glazing.area, y = Energy) +
 geom_point(size = 1L, colour = "#0c4c8a") +
 theme_minimal()
```

Visuellement, c'est selon la compacité relative et la surface vitrée que le distingue le mieux des groupes.
Selon la compacité relative, on constate principalement deux groupes. On peut également voir 12 groupes mais ceux-ci sont moins évidents.
Selon la surface vitrée, on distingue principalement 4 groupes.

### Clustering hiérarchique
Après cette analyse visuelle, nous allons utiliser des méthodes de clustering pour confirmer ou infirmer nos observations. Commençons par le clustering hiérarchique.

```{r}
hc = hclust(dist(data[c(1,2,3,4,5,7)]), method = "ward.D2")
plot(hc)
abline(h=3400,col="red")
abline(h=1300,col="red")
abline(h=880,col="red")
abline(h=200,col="red")
plot(sort(hc$height, decreasing = TRUE)[1:20])
abline(v=1.5,col="red")
abline(v=3.5,col="red")
abline(v=4.5,col="red")
abline(v=11.5,col="red")
```
Sur le dendogramme, deux classes apparaissent clairement. On peut aussi distinguer 4,5 ou 12 classes.
Sur le graphique de la variance inter-classe, on observe un saut important au passage à 2 classes. On retrouve également les résultats que l'on a obtenu avec le dendogramme en observant des sauts aux passages à 4, 5 et 12 classes.

Ces premiers outils semblent confirmer les nombres de classes qui semblent pertinents : 2, 4 et 12.

On réalise donc dans un premier temps un découpage en 2, 4 et 12 classes selon le clustering hiérarchique. On compare ces résultats avec nos observations selon plusieurs variables explicatives.

```{r}
class2 = cutree(hc, k = 2)
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
class4 = cutree(hc, k = 4)
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
class12 = cutree(hc, k = 12)
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
```

Visuellement selon la compacité relative, le découpage en 2 groupes et celui en 12 groupes semblent très pertinents. Celui en 4 groupes ne semble pas s'expliquer par la compacité relative.

```{r}
class2 = cutree(hc, k = 2)
ggplot(data) +
 aes(x = Glazing.area, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
class4 = cutree(hc, k = 4)
ggplot(data) +
 aes(x = Glazing.area, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
class12 = cutree(hc, k = 12)
ggplot(data) +
 aes(x = Glazing.area, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
```

Selon la surface vitrée, seul le découpage en 2 classes semble pertinent. On aurait pu s'attendre à un découpage en 4 classes pertinents sur ce graphique mais ce n'est pas le cas.

```{r}
class2 = cutree(hc, k = 2)
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
class4 = cutree(hc, k = 4)
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
class12 = cutree(hc, k = 12)
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
```

Finalement, le découpage en 4 classes semble pertinent selon la surface des murs.

### k-means

On utilise à présent un autre outil : k-means. Comparons les résultats avec ceux du clustering hiérarchique.

```{r}
# k-means à 2 classes
kmres2 = kmeans(data[,c(1:5,7)], centers = 2)
kmclus2 = kmres2$cluster

pairs(data[,quanti], col = kmclus2)

ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = kmclus2) +
 theme_minimal()

# clustering hierarchique à 2 classes
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
```

Pour le découpage à deux classes, les deux méthodes fournissent exactement les mêmes résultats.

```{r}
# k-means à 4 classes
kmres4 = kmeans(data[,c(1:5,7)], centers = 4)
kmclus4 = kmres4$cluster

pairs(data[,quanti], col = kmclus4)

ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = kmclus4) +
 theme_minimal()

# clustering hierarchique à 4 classes
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
```

Après plusieurs exécutions, k-means ne donne presque jamais le même résultat que le clustering hiérarchiques. Alors que le clustering hiérarchiques semble créer des classes pertinentes selon la surface des murs, le k-means réalise souvent un découpage moins pertinent. En effet, le découpage issu de k-means consiste souvent à séparer en deux les données, puis à séparer en trois un des deux groupes obtenus de façon assez arbitraire. Le découpage en 4 classes avec k-means est donc peu pertinent.


```{r}
# k-means à 12 classes
kmres12 = kmeans(data[,c(1:5,7)], centers = 12)
kmclus12 = kmres12$cluster

pairs(data[,quanti], col = kmclus12)

ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = kmclus12) +
 theme_minimal()

# clustering hierarchique à 12 classes
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
```

Selon les exécutions, k-means donne ici des résultats assez proches du clustering hiérarchique.

### Visualisation des classes sur les axes de l'ACP

On utilise ici les classes obtenues par clustering hiérarchiques car celles-ci semblaient plus naturelles visuellement.

```{r}
data$class2 = as.factor(class2)
data$class4 = as.factor(class4)
data$class12 = as.factor(class12)
res.acp <- PCA(data,scale.unit=T,quali.sup=c(6,8,10,11,12,13),quanti.sup=9,ncp=8, graph=F)
```


```{r}
plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="class2")
plot(res.acp, choix="ind", axes = c(2,3), invisible="quali", habillage="class2")
plot(res.acp, choix="ind", axes = c(1,3), invisible="quali", habillage="class2")
```

On voit ici que les données sont bien découpées en 2 classes selon le premier axe. Cela donne une bonne confiance en le découpage en 2 classes.

```{r}
plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="class4")
plot(res.acp, choix="ind", axes = c(2,3), invisible="quali", habillage="class4")
plot(res.acp, choix="ind", axes = c(1,3), invisible="quali", habillage="class4")
```

Le découpage en 4 classes se fait selon les axes 1 et 2, même si il est moins évident que celui en 2 classes. (notamment sur les classes 3 et 4 ci-dessus).

```{r}
plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="class12")
plot(res.acp, choix="ind", axes = c(2,3), invisible="quali", habillage="class12")
plot(res.acp, choix="ind", axes = c(1,3), invisible="quali", habillage="class12")
```

Ici, on peut avoir la même observation que pour le découpage en 4 classes : le découpage est moins net que celui en 2 classes et se fait selon les axes 1 et 2.


# Linear models

## Model depending on quantitatives variables

### Selection de variables par critère BIC

```{r}
model_quanti_complet = lm(Energy ~ (. - Roof.area)^2, data = data[,quanti])
summary(model_quanti_complet)
data$fitted_quanti_complet = model_quanti_complet$fitted.values
ggplot(data) +
 aes(x = fitted_quanti_complet, y = Energy) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")
```

```{r}
modselect_bic=stepAIC(model_quanti_complet,trace=TRUE,direction=c("backward"),k=log(nrow(data)))
```

```{r}
model_reduit_bic = lm(Energy ~ Relative.compactness + Surface.area + Wall.area + Overall.height + 
    Glazing.area + Relative.compactness:Surface.area + Relative.compactness:Wall.area + 
    Relative.compactness:Overall.height + Relative.compactness:Glazing.area + 
    Wall.area:Glazing.area, data = data)
anova(model_reduit_bic, model_quanti_complet)
```


```{r}
anova(model_quanti_complet, lm(Energy ~ Surface.area + Wall.area + Overall.height + Relative.compactness:Surface.area
                        + Relative.compactness:Overall.height + Surface.area:Overall.height, data = data))
```

### Selection de variable par regression regularisée

#### Ridge

```{r}
# centrage et réduction des données
eng=scale(data["Energy"],center=T,scale=T)
expli=scale(data[,c(1,2,3,5,7)],center=T,scale=T)

# création du tableau de tau
tau_seq <- seq(0, 1, by = 0.001)

# regression ridge
fitridge <- glmnet(x = expli, y = eng, family = "gaussian", alpha = 0, lambda = tau_seq, type.measure=c("mse"), intercept = F)

# récupération du tau minimum par validation croisée
ridge_cv = cv.glmnet(x = expli, y = eng, family = "gaussian", alpha = 0, lambda = tau_seq, type.measure=c("mse"), intercept = F)
tau_min_ridge = ridge_cv$lambda.min
print(tau_min_ridge)

# affichage des estimations de tau
dfridge=data.frame(tau = rep(fitridge$lambda,ncol(expli)), theta=as.vector(t(fitridge$beta)),variable=rep(colnames(expli),each=length(fitridge$lambda)))
ggplot(dfridge,aes(x=tau,y=theta,col=variable)) +
  geom_line() +
  geom_vline(xintercept = tau_min_ridge, linetype = "dotted", color = "red") +
  xlim(c(0,tau_min_ridge+0.05))
  theme(legend.position="bottom")
```

```{r}
# illustration de la meilleure valeur de tau
df2=data.frame(tau=ridge_cv$lambda,MSE=ridge_cv$cvm,cvup=ridge_cv$cvup,cvlo=ridge_cv$cvlo)
ggplot(df2)+
  geom_line(aes(x=tau,y=MSE))+
  geom_vline(xintercept = tau_min_ridge,col="red",linetype="dotted")+
  geom_line(aes(x=tau,y=cvup),col="blue",linetype="dotted")+
  geom_line(aes(x=tau,y=cvlo),col="blue",linetype="dotted")+
  xlim(c(0,tau_min_ridge+0.05))+
  ylim(c(0.115,0.155))
```


#### Lasso

```{r}
# regression lasso
fitlasso <- glmnet(x = expli, y = eng, family = "gaussian", alpha = 1, lambda = tau_seq, type.measure=c("mse"), intercept = F)

# récupération du tau minimum par validation croisée
lasso_cv = cv.glmnet(x = expli, y = eng, family = "gaussian", alpha = 1, lambda = tau_seq, type.measure=c("mse"), intercept = F)
tau_min_lasso = lasso_cv$lambda.min
print(tau_min_lasso)

# affichage des estimations de tau
dflasso=data.frame(tau = rep(fitlasso$lambda,ncol(expli)), theta=as.vector(t(fitlasso$beta)),variable=rep(colnames(expli),each=length(fitlasso$lambda)))
ggplot(dflasso,aes(x=tau,y=theta,col=variable)) +
  geom_line() +
  geom_vline(xintercept = tau_min_lasso, linetype = "dotted", color = "red") +
  xlim(c(0,tau_min_lasso+0.01))
  theme(legend.position="bottom")
```

```{r}
# illustration de la meilleure valeur de tau
df3=data.frame(tau=lasso_cv$lambda,MSE=lasso_cv$cvm,cvup=lasso_cv$cvup,cvlo=lasso_cv$cvlo)
ggplot(df3)+
  geom_line(aes(x=tau,y=MSE))+
  geom_vline(xintercept = tau_min_lasso,col="red",linetype="dotted")+
  geom_line(aes(x=tau,y=cvup),col="blue",linetype="dotted")+
  geom_line(aes(x=tau,y=cvlo),col="blue",linetype="dotted")+
  xlim(c(0,tau_min_lasso+0.05))+
  ylim(c(0.115,0.155))
```


## Model depending on all variables

```{r}
model_complet = lm(Energy ~ (. - Roof.area)^2, data = data[,c(1:9)])
summary(model_complet)
data$fitted_complet = model_complet$fitted.values
ggplot(data) +
 aes(x = fitted_complet, y = Energy) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")

ggplot(data) +
 aes(x = fitted_complet, y = Energy, col = Glazing.area.distr) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")

ggplot(data) +
 aes(x = fitted_complet, y = Energy, col = orientation) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")
```

```{r}
model_reduit1 = lm(Energy ~ . - Roof.area - orientation, data = data[,c(1:9)])
anova(model_complet, model_reduit1)
summary(model_reduit1)
```

```{r}
selectf = regsubsets(Energy ~ (. - Roof.area)^2, data = data[,c(1:9)],nbest=1,nvmax=10,method="forward")
plot(selectf,scale="bic",main="Forward BIC")
plot(selectf,scale="Cp",main="Forward Cp")
plot(selectf,scale="adjr2",main="Forward adjusted R²")

selectb = regsubsets(Energy ~ (. - Roof.area)^2, data = data[,c(1:9)],nbest=1,nvmax=10,method="backward")
plot(selectb,scale="bic",main="Backward BIC")
plot(selectb,scale="Cp",main="Backward Cp")
plot(selectb,scale="adjr2",main="Backward adjusted R²")
```

```{r}
# model_reduit2
# anova()
```
```{r}
# Modéle linéaire généralisée
# Définition de Energy.efficiencyBIs
data.mlg = data.frame(data, Energy.efficiency.bis = rep(0, nrow(data)))
data.mlg$Energy.efficiency.bis[which(data.mlg$Energy.efficiency == "A" | data.mlg$Energy.efficiency == "B")] = "1"
data.mlg$Energy.efficiency.bis[which(data.mlg$Energy.efficiency !="A" & data.mlg$Energy.efficiency !="B" )] = "0"
data.mlg$Energy.efficiency.bis = as.factor(data.mlg$Energy.efficiency.bis)
data.mlg<-data.mlg[,c(-4,-9,-10)]
```

```{r}
#Statistique Descriptive
boxplot(Relative.compactness~ Energy.efficiency.bis,data=data.mlg)
boxplot(Surface.area~ Energy.efficiency.bis,data=data.mlg)
boxplot(Wall.area~ Energy.efficiency.bis,data=data.mlg)
boxplot(Overall.height~ Energy.efficiency.bis,data=data.mlg)
boxplot(Glazing.area~ Energy.efficiency.bis,data=data.mlg)
mosaicplot(table(data.mlg[,c("Energy.efficiency.bis","orientation")]))
```
```{r}
# Ajustement du modèle linéaire généralisé additif
mlg_rg <- glm(Energy.efficiency.bis~(.-Roof.area),data=data.mlg,family=binomial(link=logit))
summary(mlg_rg)
```

```{r}
#Calcul de pseudo R2 de mlg_rg
pseudoR2 = 1 - ( mlg_rg$deviance/mlg_rg$null.deviance)
print("Pseudo R2 ")
print(pseudoR2)
```

```{r}
print("############################  AIC  #############################")
step.backward_aic = step(mlg_rg)
print('')
print("############################  BIC  #############################")
step.backward_bic = step(mlg_rg, direction="backward",k=log(nrow(SAheart)))

```

```{r}
#####Choix du sous modéle 
### Comparaison du modèle complet  avec le sous modèle AiC
mlg_rg_best_aic <- glm(Energy.efficiency.bis~Relative.compactness+Glazing.area+Overall.height+Glazing.area.distr,family=binomial(link=logit),data=data.mlg)
summary(mlg_rg_best_aic)
anova(mlg_rg_best_aic,mlg_rg,test="Chisq")
```

La pvaleur étant de 0.55 donc on garde le modèle AIC
```{r}

# On note que le sous modèle bic est un sous modèle du modèle AIC
#### Comparaison du modèle AIC  avec le sous modèle BIC
mlg_rg_best_bic <- glm(Energy.efficiency.bis~Relative.compactness+Glazing.area+Overall.height,family=binomial(link=logit),data=data.mlg)
summary(mlg_rg_best_bic)
anova(mlg_rg_best_bic,mlg_rg_best_aic,test="Chisq")
```

```{r}
#Ajustement du modèle complet avec intéraction 
mlg_rg_inter <- glm(Energy.efficiency.bis~.^2,data=data.mlg,family=binomial(link="logit"))
summary(mlg_rg_inter)
```


```{r}
#Calcul de pseudo R2
pseudoR2 = 1 - ( mlg_rg_inter$deviance/mlg_rg_inter$null.deviance)
print("Pseudo R2 ")
print(pseudoR2)
```

```{r}
print("############################  AIC  #############################")
step.backward_aic = step(mlg_rg_inter)
print('')
print("############################  BIC  #############################")
step.backward_bic = step(mlg_rg_inter, direction="backward",k=log(nrow(SAheart)))

```

```{r}
#####Choix du sous modéle 
### Comparaison du modèle complet  avec le sous modèle AiC
mlg_inter_best_aic <- glm(Energy.efficiency.bis ~ Relative.compactness + Surface.area + 
    Wall.area + Overall.height + orientation + Glazing.area + 
    Glazing.area.distr + Relative.compactness:Glazing.area + 
    Surface.area:Wall.area + Surface.area:orientation + Surface.area:Glazing.area.distr + 
    Wall.area:orientation + Wall.area:Glazing.area + Overall.height:orientation,family=binomial(link=logit),data=data.mlg)
summary(mlg_inter_best_aic)
anova(mlg_inter_best_aic,mlg_rg_inter,test="Chisq")
```

La pvaleur étant de 0.9577 on ne rejette donc pas H0
ON conserve le sous  modèle AIC
```{r}
#### Puisque dans ce cas le modèle BIC n'est pas un sous modèle du modèlé AIC
#### On  compare d'abord le Modèle BIC avec le modèle complet et s'il est retenu
### On compare leurs pseudoR2 pour déterminer le modèle à choisir
#### Comparaison du modèle complet avec intéraction  avec le sous modèle BIC avec intéraction 
mlg_inter_best_bic <- glm(Energy.efficiency.bis ~ Relative.compactness + Surface.area + 
    Overall.height + Glazing.area + Relative.compactness:Glazing.area + 
    Surface.area:Overall.height,family=binomial(link=logit),data=data.mlg)
summary(mlg_inter_best_bic)
anova(mlg_inter_best_bic,mlg_rg_inter,test="Chisq")
```

La pvaleur étant de 0.2507 on peut réduire le modèle complét avec intéraction avec le sous modèle BIC

```{r}
# Comparaison des pseudo R2 pour le choix du sous modèle
pseudoR2_aic = 1 - mlg_inter_best_aic$deviance/mlg_inter_best_aic$null.deviance
pseudoR2_bic = 1 -mlg_inter_best_bic$deviance/mlg_inter_best_bic$null.deviance
#Booléan attestant de la supériorité du pseudoR2 du sous modèle AIC
aic_sup_bic = pseudoR2_aic>pseudoR2_bic
print(aic_sup_bic)
```


Donc on retient le sous modèle AIC avec intéraction contre celui du bic avec intéraction
```{r}
# Comparaison du modèle AIC sans intéraction avec le modèle AIC avec intéraction 
# Dans ce cas précis les modèle sans intéraction est un sous modèle de celui avec intéraction donc
# on peut réaliser un test de sous modèle 
anova(mlg_rg_best_aic,mlg_inter_best_aic,test="Chisq")
```

La pvaleur étant de 0.006016 on rejette H0
Donc on conserve mlg_inter_best_aic

