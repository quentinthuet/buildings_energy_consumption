---
title: "Projet de statistiques : prédiction de la consommation énergétique de bâtiments"
output:
  pdf_document:
    toc: true
    number_sections: true
    toc_depth: 3
  html_document:
    df_print: paged
toc-title: "Sommaire"
geometry: margin=2cm
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center", results="hold", cache = TRUE, fig.dim=c(8,3))
library(ggfortify)
library(VGAM)
library(ROCR)
library(tidyverse)
library(ggplot2)
library(esquisse)
library(FactoMineR)
library(leaps)
library(MASS)
library(glmnet)
library(gridExtra)
library(bestglm)
library(plotly)
library(caret)
library(factoextra)
```

# Introduction et présentation du jeu de données

L'objectif de ce projet est de prédire la consommation énergétique de différents
bâtiments en fonction de certaines de leurs caractéristiques (forme, surface,
fenêtres, orientation...). Cette consommation d'énergie est exprimable sous forme
quantitative (numériquement) ou qualitative (en classes de A à G).

Nous commencerons par une première partie d'analyse naïve de notre jeu de données,
avant de rentrer plus en profondeur dans la construction de modèles de prédiction.

Les modèles que nous avons implémentés sont des modèles linéaires (classiques 
et généralisés), ainsi que des modèles non linéaires (classification hiérarchique, 
arbre optimal, forêts aléatoires).

Nous disposons pour notre étude d'un jeu de données de 768 bâtiments.
Pour chaque bâtiment, nous possédons les 10 caractéristiques suivantes :

* Quantitatives :
  + `Relative.compactness` : compacité relative à un cube de même volume ($RC = 6 \times V^{0.66} \times A^{-1}$ avec $V$ et $A$ respectivement le volume et l'aire totale du batiment : murs + toit + sol)
  + `Surface.area` : surface totale (sol + murs + toit)
  + `Wall.area` : surface de mur extérieurs
  + `Roof.area` : surface de toit
  + `Glazing.area` : Surface vitrée (en pourcentage de la surface au sol)
  + `Energy` : Énergie consommée
* Catégorielles :
  + `Overall.height` : hauteur du batiment (soit 3.5, soit 7 m)
  + `orientation` : orientation de la maison (Nord, Sud, Est, Ouest)
  + `Glazing.area.distr` : Distribution des vitres (uniforme, ou davantage d'un coté)
  + `Energy.efficiency` : Indicateur de l'énergie consommée (de A (meilleur) à G (pire))
  
On cherchera donc dans les prochaines parties à prédire les variables `Energy` et `Energy.efficiency`. 

# Analyse des données

Nous allons dans un premier temps réaliser quelques statistiques exploratoires sur toutes nos variables.

## Statistiques descriptives

```{r, echo=FALSE}
setwd("/home/leo/GoogleDrive/Cours/INSA_4A/Projet")
```
```{r}
# Lecture jeu de données, mise sous forme de facteur et corrections
data = read.table("DataEnergy-Student.csv", header = TRUE, sep = ",")
data$Glazing.area.distr = as.factor(factor(data$Glazing.area.distr))
data$Energy.efficiency = as.factor(data$Energy.efficiency)
data$orientation = as.factor(data$orientation)
data$Overall.height = factor(data$Overall.height, ordered = TRUE)
data$Glazing.area[which(data$Glazing.area.distr == 0)] = 0
# Informations sur le jeu de données
s = summary(data[,c(6,5,8,9,10)])
colnames(s)[5] = "Energy.eff" ; s
# Séparation des variables quantitatives et qualitatives
quanti = c(1, 2, 3, 4, 7, 9) ; quali = c(5, 6, 8, 10) ; allvariables = 1:10
```

On peut noter qu'il y a
le même nombre de bâtiments pour chaque orientation et pour chaque hauteur.
La distribution des fenêtres est aussi répartie équitablement entre les bâtiments,
sauf pour ceux sans fenêtres (modalité 0) qui sont moins nombreux.

L'énergie consommée s'étale de 10 à 95, avec une moyenne de 46. Les bâtiment avec
une faible consommation d'énergie (A ou B) sont assez nombreux (41\% des bâtiments).

```{r, fig.dim=c(8,4)}
par(mfrow=c(1,2))
plot(2*data$Roof.area + data$Wall.area, data$Surface.area, pch='.',
     main = "Relation entre les surfaces",
     xlab = "2 * Surface de toit + Surface murée",
     ylab = "Surface totale")
plot(1/(data$Surface.area), data$Relative.compactness, pch='.',
     main = "Relation entre compacité et surface",
     xlab = "Inverse de la surface totale",
     ylab = "Compacité relative")
```

La premier graphe nous montre que les variables `Roof.area`, `Wall.area` et `Surface.area` sont liées par la relation :
$\texttt{Surface.area} = 2 \times \texttt{Roof.area} + \texttt{Wall.area}$.
Ainsi, nous n'étudierons pas la variable `Roof.area` plus en détails par la suite, étant donnée
qu'elle peut être directement obtenue depuis d'autres variables.
<!-- Virer variable Roof.area ? -->

On observe sur le second graphe une relation linéaire entre la compacité relative et l'inverse de la surface totale. Ça n'est pas étonnant au vu de la formule de la compacité relative : $RC = 6 \times V^{0.66} \times A^{-1}$. Cependant, ici la relation linéaire n'est pas exacte comme dans le cas précédent : il y a potentiellement de l'information contenue dans les deux variables. Nous n'en écarterons donc pas une pour notre étude.

Nous avons également essayé de voir quelles étaient les variables les plus influentes sur l'énergie consommée.

```{r, fig.dim=c(8,4.5)}
par(mfrow = c(2,2), mar = c(4,4,2,1))
plot(Energy ~ Relative.compactness, data = data, pch = '.')
plot(Energy ~ Surface.area, data = data, pch = '.')
plot(Energy ~ Wall.area, data = data, pch = '.')
boxplot(Energy ~ Overall.height, data = data, pch = '.')
```

On voit que les variables liées à la forme du bâtiment jouent un rôle important
dans la consommation d'énergie. Ainsi, les bâtiments les moins consommateurs sont
ceux qui sont : moins hauts, plus compacts, de surface totale plus importante,
et de surface murée plus faible.

```{r, fig.dim=c(8,4.5)}
layout(matrix(c(1,2,3,2), 2, 2, byrow = TRUE))
par(mar = c(4,4,2,1))
boxplot(Energy ~ orientation, data = data)
plot(Energy ~ Glazing.area, data = data)
boxplot(Energy ~ Glazing.area.distr, data = data)
```

On voit ici que l'orientation ne semble pas avoir d'influence sur l'énergie consommée.

Pour la surface vitrée, on voit que les bâtiments sans vitres (modalité 0 de `Glazing.area.distr`
et valeur 0 de `Glazing.area`) consomment comment on s'y attend moins d'énergie que les bâtiments vitrés.
En revanche, la distribution des vitres ne semble pas avoir de réel impact
(modalités 1 à 5 de `Glazing.area.distr`). Il semble cependant qu'il y ait une petite augmentation
de la consommation avec l'augmentation de la surface vitrée.

Afin d'étudier d'éventuelles corrélations entre nos variables, nous allons
maintenant mener une analyse en composantes principales.

## Analyse en Composantes Principales (ACP)

On souhaite réaliser une ACP afin de se ramener à un nombre de dimensions plus faible.
Nous allons pour cela utiliser le package `FactoMineR` qui contient toutes les
fonctions nécessaires à la réalisation de notre ACP.
On cherche d'abord combien d'axes principaux nous allons avoir besoin.

```{r, fig.dim=c(8,3.5)}
library("FactoMineR")
par(mfrow=c(1,2))
res.acp <- PCA(data,scale.unit=T,quali.sup=quali,quanti.sup=9,ncp=8, graph=F)
barplot(res.acp$eig[,"percentage of variance"], main="Pourcentage de variance",
        names.arg = seq(1,5), xlab = "Composantes principales")
barplot(res.acp$eig[,"cumulative percentage of variance"],
        main="Pourcentage de variance cumulée",
        names.arg = seq(1,5), xlab = "Composantes principales")
abline(h = 95, col = "red")
print(paste("Pourcentage d'inertie expliquée par les trois premiers axes :",
            res.acp$eig[,"cumulative percentage of variance"][3]))
```

On voit sur le premier graphe que l'inertie portée par les trois premiers axes principaux est prépondérante par rapport aux autres. Ils expliquent presque 99\% de l'inertie. Les deux premiers axes ne portent eux que 82\% de l'inertie. Ne choisir que deux axes effacerait trop d'informations. Nous allons donc poursuivre notre analyse sur les trois premiers axes principaux.

Les graphes des variables nous donnent des informations intéressantes sur les variables corrélées.

```{r, fig.dim=c(6,6)}

layout_matrix = matrix(c(1,2,3,3), 2, 2, byrow = TRUE)
gg1 = plot.PCA(res.acp, choix="var", axes = c(1,2), new.plot = FALSE,
               title = "Variables (axes 1/2)")
gg2 = plot.PCA(res.acp, choix="var", axes = c(1,3), new.plot = FALSE,
               title = "Variables (axes 1/3)")
gg3 = plot.PCA(res.acp, choix="var", axes = c(2,3), new.plot = FALSE,
               title = "Variables (axes 2/3)")
grid.arrange(gg1,gg2,gg3,layout_matrix=layout_matrix)
```

Les variables `Relative.compactness`, `Surface.area` et `Roof.area` semblent être plutôt portées par le premier axe principal (en positif pour les deux premières, négatif pour les deux autres).

Le second axe porte principalement la variable `Wall.area`, et le troisième la variable `Glazing.area`.

Finalement, les deux premiers axes ont plutôt trait à la forme du bâtiment (surface au sol pour le premier et surface murée pour le second), tandis que le troisième axe correspond à la surface vitrée.

Ainsi, l'énergie dépensée dépend d'abord de la forme du bâtiment, et ensuite de la surface vitrée.

Nous pouvons également observer les graphes des individus. Nous représentons les différentes classes énergétiques par couleur.


```{r, fig.dim=c(7,4)}
gg1 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali",
           habillage="Energy.efficiency", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8), legend.position="none")
gg2 = plot(res.acp, choix="ind", axes = c(2,3), invisible="quali",
           habillage="Energy.efficiency", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8), legend.position="none")
gg3 = plot(res.acp, choix="ind", axes = c(1,3), invisible="quali",
           habillage="Energy.efficiency", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8)) + guides(color=guide_legend(ncol=2))
grid.arrange(gg1,gg2,gg3,layout_matrix = layout_matrix)
```

On peut voir sur le premier et le troisième graphique que l'axe 1 marque une claire séparation entre les classes A, B, C et les classes D, E, F, G.

Les bâtiments à la consommation énergétique la plus faible possèdent des coordonnées négatives pour la première composante. Ils sont plus bas et plus compacts, comme on peut le voir sur les graphiques suivants :

```{r, fig.dim=c(7,3)}
gg1 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali",
           habillage="Relative.compactness", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8))
gg2 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali",
           habillage="Overall.height", label = "none") +
  theme(text = element_text(size=8))
grid.arrange(gg1,gg2,ncol=2)
```

Ainsi, les maisons plus étalées sur le sol possèdent les meilleures performances énergétiques.

## Clustering de variables

Nous allons essayer de voir si nous pouvons classer nos variables en différents
groupes qui nous permettraient de prédire leur consommation énergétique.

### Analyse visuelle

Nous menons d'abord une analyse visuelle au sein de nos différentes variables 
afin de mettre en évidence de potentiels groupes.

```{r, fig.dim=c(6,3)}
gg1 = ggplot(data) +
  aes(x = Relative.compactness, y = Energy) +
  geom_point() + theme_minimal()
gg2 = ggplot(data) +
  aes(x = Glazing.area, y = Energy) +
  geom_point() + theme_minimal()
grid.arrange(gg1,gg2,ncol=2)
```

Visuellement, c'est selon la compacité relative et la surface vitrée que l'on distingue le mieux des groupes.

Avec la compacité relative, on constate principalement deux groupes. On peut également voir 12 groupes mais ceux-ci sont moins évidents.

Avec la surface vitrée, on distingue principalement quatre groupes avec deux sous-groupes
à chaque fois.

### Clustering hiérarchique

Après cette analyse visuelle, nous allons utiliser des méthodes de clustering pour confirmer ou infirmer nos observations. Commençons par le clustering hiérarchique.

```{r, fig.dim=c(6,3.5), fig.show='hold'}
par(mfrow=c(1,2))
par(mar = c(4,4,2,1))
hc = hclust(dist(data[c(1,2,3,4,5,7)]), method = "ward.D2")
plot(hc, xlab = "")
abline(h=3400,col="red")
abline(h=1300,col="red")
abline(h=880,col="red")
abline(h=200,col="red")
# par(mar = c(4,4,4,0))
plot(sort(hc$height, decreasing = TRUE)[1:20],
     ylab = "Variance inter-classe")
abline(v=1.5,col="red")
abline(v=3.5,col="red")
abline(v=4.5,col="red")
abline(v=11.5,col="red")
```
Sur le dendogramme, deux classes apparaissent clairement. On peut aussi distinguer 4,5 ou 12 classes.
Sur le graphique de la variance inter-classe, on observe un saut important au passage à 2 classes. On retrouve également les résultats que l'on a obtenu avec le dendogramme en observant des sauts aux passages à 4, 5 et 12 classes.

Ces premiers outils semblent confirmer les nombres de classes qui semblent pertinents : 2, 4 et 12.

On réalise donc dans un premier temps un découpage en 2, 4 et 12 classes selon le clustering hiérarchique. On superpose ensuite ces classes sur nos graphes précédents.

```{r, fig.height=2.5}
class2 = cutree(hc, k = 2)
gg1 = ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
class4 = cutree(hc, k = 4)
gg2 = ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
class12 = cutree(hc, k = 12)
gg3 = ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
grid.arrange(gg1,gg2,gg3,ncol=3)
```

En regardant la compacité relative, les découpages en 2 et 12 classes semblent très pertinents. Celui en 4 classe l'est moins. On peut un peu mieux voir la séparation des 4 classes en regardant la surface murée ci-dessous. On aurait tout de même envie de découper en plus de classes dans ce graphique.

```{r, fig.dim=c(4,3)}
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
```

Le découpage en 2 classes semble très marqué, nous aimerions savoir si il n'est pas lié à la seule variable à deux modalités de notre jeu de donnée : la hauteur du batiment.

```{r}
table(class2, data$Overall.height)
```

La table de contingence confirme bien notre intuition : les deux classes correspondent exactement aux deux hauteurs de bâtiments de notre jeu de données.

### k-means

On utilise à présent un nouvel outil : les k-means. Nous souhaitons le comparer
au clustering hiérarchique.

```{r}
# k-means à 2 classes
set.seed(42)
kmres2 = kmeans(data[,c(1:5,7)], centers = 2)
kmclus2 = kmres2$cluster
table(kmres2$cluster, data$Overall.height)
```
Pour deux classes, les deux méthodes fournissent exactement la même découpe : selon la hauteur.

```{r}
# k-means à 4 classes
set.seed(42)
kmres4 = kmeans(data[,c(1:5,7)], centers = 4)
kmclus4 = kmres4$cluster

ggplot(data) +
  aes(x = Wall.area, y = Energy,
      colour = as.factor(kmclus4), shape = as.factor(class4)) +
  scale_shape_manual(values=1:nlevels(as.factor(class4))) +
  labs(color = "K-means", shape = "Clustering hiérarchique") +
  geom_point(size = 2) +
  theme_minimal()
```

Après plusieurs exécutions, les k-means ne donne presque jamais le même résultat que le clustering hiérarchique pour 4 classes. Ils réalisent souvent un découpage moins pertinent dans la surface des murs.

```{r}
# k-means à 12 classes
set.seed(42)
kmres12 = kmeans(data[,c(1:5,7)], centers = 12)
kmclus12 = kmres12$cluster

ggplot(data) +
  aes(x = Wall.area, y = Energy, color = as.factor(kmclus12), shape = as.factor(class12)) +
  scale_shape_manual(values=1:nlevels(as.factor(class12))) +
  geom_point(size = 2) +
  labs(color = "K-means", shape = "Clustering hiérarchique") +
  theme_minimal() +
  guides(color=guide_legend(ncol=3), shape=guide_legend(ncol=3))
```

C'est assez dur à visualiser graphiquement à cause du nombre de classes, mais les k-means donnent ici des résultats plus proches du clustering hiérarchique. Les séparations dépendent toutefois des executions, et semblent globalement un peu moins bien définies.

### Visualisation des classes sur les axes de l'ACP

On va essayer de projeter les classes obtenues par clustering sur l'ACP afin de voir si les découpages sont pertinents. Nous utilisons les classes obtenues par clustering hiérarchiques car celles-ci nous semblaient plus naturelles visuellement.

```{r}
data_classes = data
data_classes$class2 = as.factor(class2)
data_classes$class4 = as.factor(class4)
data_classes$class12 = as.factor(class12)
res.acp_classes=PCA(data_classes,scale.unit=T,quali.sup=c(quali,11,12,13),quanti.sup=9,graph=F)
gg1 = fviz_pca_ind(res.acp_classes, c(1,2), habillage="class12", labels = F)
gg2 = fviz_pca_ind(res.acp_classes, c(1,3), habillage="class12", labels = F)
grid.arrange(gg1+theme(legend.position="none"),gg2+theme(legend.position="none"),ncol=2)
```

Les 12 groups sont visibles très clairement sur l'ACP. Ils sont très séparés selon le premier axe principal. Ainsi, les clusters sont principalement réalisés selon la forme du bâtiment (`Surface.area`, `Relative.compactness`, `Overall.height`).

# Modèles linéaires

## Modèle fonction des variables quantitatives

Nous étudierons dans un premier temps des modèles linéaires expliquant la variable quantitative `Energy` en fonction des variables *quantitatives* uniquement. Comme expliqué précedement, nous écartons `Roof.area` car elle rendrait notre modèle singulier.

### Modèle avec interactions

Nous construisons d'abord naïvement premier modèle contenant les variables quantitatives et leurs interactions.

<!-- ADD A QQ-PLOT ? -->

```{r, fig.dim=c(8,3)}
model_quanti_complet = lm(Energy ~ (. - Roof.area)^2, data = data[,quanti])
r.sq = summary(model_quanti_complet)$r.squared ; paste("R² =", r.sq)
data$fitted_quanti_complet = model_quanti_complet$fitted.values
ggplot(data) + 
  aes(x = fitted_quanti_complet, y = Energy) +
  geom_point(size = 1L) + 
  geom_abline(slope = 1) +
  labs(title = "Regression linéaire de `Energy` en fonction des variables quantitatives",
       x = "Valeurs ajustées") +
  theme_minimal()
```

Le modèle obtenu semble déjà bien passer au sein des données : on trouve un $R^2$ de 0.8952.

Cependant, ce modèle conserve beaucoup de variables, on peut donc se demander si elles sont toutes pertinentes. Nous allons donc essayer ne n'en conserver que certaines.

### Selection de variables par critère BIC

Nous allons réaliser dans un premier temps une sélection de variables par critère BIC.

```{r}
modselect_quanti_bic_back = stepAIC(model_quanti_complet,trace=FALSE,direction=c("backward"),k=log(nrow(data)),)
paste("Energy ~", paste(dimnames(modselect_quanti_bic_back$qr$qr)[[2]][-1], collapse=" + "))
```

Le modèle selectionné conserve nos 5 des variables quantitatives, mais supprime certaines de de leur interactions. Afin de s'assurer que l'on peut simplifier notre modèle, on réalise un test de sous-modèle entre le modèle complet et le modèle selectionné.

```{r}
anova(modselect_quanti_bic_back, model_quanti_complet)
r.sq = summary(modselect_quanti_bic_back)$r.squared ; paste("R² =", r.sq)
```

On obtient une p-valeur de 0.2864. On ne rejette donc pas notre modèle selectionné au seuil de 5 \%.
Ainsi, notre modèle possède un $R^2$ de 0.8943, ce qui est à peine plus faible que ce que nous avions avec toutes nos variables.

### Selection de variable par regression regularisée

On peut également tenter de sélectionner nos variables par régression régularisée.
Nous nous contenterons d'étudier le modèle sans interactions car la fonction que nous utiliserons ne traite pas de priorisation entre les effets principaux et les interactions.

```{r}
# centrage et réduction des données
energy = scale(data["Energy"],center=T,scale=T)
# f = as.formula(paste("Energy ~ (", paste(dimnames(data[,c(1,2,3,7)])[[2]], collapse=" + "), ")^2"))
# expli = scale(model.matrix(f,data)[,-1],center=T,scale=T)
expli = scale(data[quanti[-6]],center=T,scale=T)

# création du tableau de tau
tau_seq <- seq(0, 0.1, by = 0.0001)
```


#### Ridge

```{r, eval=FALSE}
fitridge <- glmnet(x = expli, y = energy, family = "gaussian", alpha = 0, lambda = tau_seq, intercept = F)

# récupération du tau minimum par validation croisée
ridge_cv = cv.glmnet(x = expli, y = energy, family = "gaussian", alpha = 0, lambda = tau_seq, intercept = F)
tau_min_ridge = ridge_cv$lambda.min
print(tau_min_ridge)

# affichage des estimations de tau
dfridge=data.frame(tau = rep(fitridge$lambda,ncol(expli)),
                   theta=as.vector(t(fitridge$beta)),
                   variable=rep(colnames(expli),each=length(fitridge$lambda)))
ggplot(dfridge,aes(x=tau,y=theta,col=variable)) +
  geom_line() +
  geom_vline(xintercept = tau_min_ridge, linetype = "dotted", color = "red") +
  theme(legend.position="right")
```

```{r, eval=FALSE}
# illustration de la meilleure valeur de tau
df2=data.frame(tau=ridge_cv$lambda,MSE=ridge_cv$cvm,cvup=ridge_cv$cvup,cvlo=ridge_cv$cvlo)
ggplot(df2)+
  geom_line(aes(x=tau,y=MSE))+
  geom_vline(xintercept = tau_min_ridge,col="red",linetype="dotted")+
  geom_line(aes(x=tau,y=cvup),col="blue",linetype="dotted")+
  geom_line(aes(x=tau,y=cvlo),col="blue",linetype="dotted")
```

La régression Ridge ne nous donne pas vraiment de résultats intéressant, il est difficile de voir clairement quelles variables écarter. Nous allons donc essayer une régression lasso.

#### Lasso

```{r}
fitlasso <- glmnet(x = expli, y = energy, family = "gaussian", alpha = 1, lambda = tau_seq, intercept = F)
dflasso=data.frame(tau = rep(fitlasso$lambda,ncol(expli)),
                   theta=as.vector(t(fitlasso$beta)),
                   variable=rep(colnames(expli),each=length(fitlasso$lambda)))
ggplot(dflasso,aes(x=tau,y=theta,col=variable)) +
  geom_line() +
  geom_vline(xintercept = 0.02, linetype = "dotted", color = "red") +
  theme(legend.position="right")
```

```{r, eval=FALSE}
# récupération du tau minimum par validation croisée
lasso_cv = cv.glmnet(x = expli, y = energy, family = "gaussian", alpha = 1, lambda = tau_seq, intercept = F)
tau_min_lasso = lasso_cv$lambda.min
print(tau_min_lasso)
# illustration de la meilleure valeur de tau
df3=data.frame(tau=lasso_cv$lambda,MSE=lasso_cv$cvm,cvup=lasso_cv$cvup,cvlo=lasso_cv$cvlo)
ggplot(df3)+
  geom_line(aes(x=tau,y=MSE))+
  geom_vline(xintercept = tau_min_lasso,col="red",linetype="dotted")+
  geom_line(aes(x=tau,y=cvup),col="blue",linetype="dotted")+
  geom_line(aes(x=tau,y=cvlo),col="blue",linetype="dotted")
```

Certains variables s'écrasent bien à 0. En choisissant un seuil de 0.02, la régularisation écarterait les variables `Surface.area` et `Relative.compactness`. Cependant ce seuil est arbitraire. En essayant de le choisir par validation croisée pour minimiser le critère MSE, nous trouvons 0. Cela signifierait qu'il faudrait conserver toutes les variables. Cela serait cohérent avec les résultats de la sélection par critère BIC, qui conservait toutes les variables (plus certaines interactions). Le fait de ne pas pouvoir tester les interactions nous limite sur les conclusions que nous pouvons tirer des régression régularisées.

Nous n'avons jusqu'à présent considéré que les variables quantitatives. Nous allons maintenant essayer de voir si les variables qualitatives de notre jeu de données ne pourraient pas nous apporter des informations supplémentaires.

## Modèle délendant de toutes les variables

On construit un modèle complet avec interactions, et on teste un sous-modèle sans interactions pour voir si on pourrait s'en passer.

```{r}
model_complet = lm(Energy ~ (. - Roof.area)^2, data = data[,c(1:9)])
data$fitted_complet = model_complet$fitted.values
model_no_interactions = lm(Energy ~ . - Roof.area, data = data[,c(1:9)])
anova(model_complet, model_no_interactions)
```

La p-valeur est très faible : on doit conserver des interactions. Nous allons essayer de voir si nous ne pourrions pas nous en passer de certaines grâce à un algorithme de sélection de variables.

```{r}
modselect_bic_back = stepAIC(model_complet,trace=FALSE,direction=c("backward"),k=log(nrow(data)))
formula = paste("Energy ~", paste(dimnames(modselect_bic_back$qr$qr)[[2]][-1], collapse=" + ")) ; formula
```

Ainsi la sélection laisse complètement de côté la variable `orientation`, et supprime également certaines interactions. On réalise un test de sous-modèle afin de savoir si nous pouvons simplifier le modèle complet.

```{r}
anova(modselect_bic_back, model_complet)
summary(modselect_bic_back)
```

On obtient une p-valeur supérieure à 99\%, on ne rejette donc pas le modèle réduit, et on peut simplifier le modèle.

## Pouvoir de prédiction du modèle

Maintenant qu'on a déterminé les variables d'intérêt, nous allons tester le pouvoir de prédiction de notre modèle. Pour cela, nous allons faire de la validation croisée.

```{r}
set.seed(42)
train.control = trainControl(method = "cv", number = 10, p = 0.8)
model_cv = train(modselect_bic_back$terms, data = data, method = "lm", trControl = train.control)
print(model_cv)
```

On obtient un $R^2$ de presque 90\%, le modèle passe donc bien par les données. De plus, l'erreur moyenne absolue de moins de 5. En sachant que la variable `Energy` s'étale de 10 à 95, notre erreur est assez faible : elle représente moins de 6\% de l'étendue de nos données.

# Modèle linéaire généralisée

### Mise en forme de la data Frame
```{r}
# Modéle linéaire généralisée
# Définition de Energy.efficiencyBIs
new_data <- data[,c(-11,-12,-13,-14,-15)]
data.mlg = data.frame(new_data, Energy.efficiency.bis = rep(0, nrow(new_data)))
data.mlg$Energy.efficiency.bis[which(data.mlg$Energy.efficiency == "A" | data.mlg$Energy.efficiency == "B")] = "1"
data.mlg$Energy.efficiency.bis[which(data.mlg$Energy.efficiency !="A" & data.mlg$Energy.efficiency !="B" )] = "0"
data.mlg$Energy.efficiency.bis = as.factor(data.mlg$Energy.efficiency.bis)
data.mlg<-data.mlg[,c(-4,-9,-10)]
```

### Statistique descriptive 
```{r}
#Statistique Descriptive
boxplot(Relative.compactness~ Energy.efficiency.bis,data=data.mlg)
boxplot(Surface.area~ Energy.efficiency.bis,data=data.mlg)
boxplot(Wall.area~ Energy.efficiency.bis,data=data.mlg)
boxplot(Overall.height~ Energy.efficiency.bis,data=data.mlg)
boxplot(Glazing.area~ Energy.efficiency.bis,data=data.mlg)
mosaicplot(table(data.mlg[,c("Energy.efficiency.bis","orientation")]))
```
L'analyse descriptive du modèle linéaire généralisé  par rapport à la variable 
Energy.efficiency.bis nous permet de noter les points suivant :

* Les individus qui ont une meilleure Energy.efficiency.bis ont une Relative compactness faible.
* Les individus qui ont une meilleure Energy.efficiency.bis ont une Surface.area plus grande.
* Les individus qui ont une meilleure Energy.efficiency.bis ont des surface de Wall.area faible.
* Les batiments ayant une overall height faible ont une meilleur Energy.efficiency.bis
    
## Modèle linéaire généralisé additif
Puisque, les variables Surface.area, Wall.area et la Roof.area sont liées, nous allons l'enlever du jeu de données.
En outre, l'analyse statistique nous a permis d'identifier que toutes les variables avaient des effets sur l'Energy.efficiency.bis
donc nous allons considérer le modèle additif
### Ajustement du modèle
```{r}
# Ajustement du modèle linéaire généralisé additif
mlg_rg <- glm(Energy.efficiency.bis~.,data=data.mlg,family=binomial(link=logit))
summary(mlg_rg)
```
### Calcul du pseudo R2
```{r}
#Calcul de pseudo R2 de mlg_rg
pseudoR2 = 1 - ( mlg_rg$deviance/mlg_rg$null.deviance)
print("Pseudo R2 ")
print(pseudoR2)
```
Le Pseudo R2 trouvé est de 0.712, alors on peut modéliser ce problème par un MLG.
### Recherche de sous modèle
```{r}
print("############################  AIC  #############################")
mlg.BIC <- bestglm(data.mlg, family = binomial, IC = "BIC")
mlg.BIC$BestModel
print('')
print("############################  BIC  #############################")
mlg.AIC <- bestglm(data.mlg, family = binomial, IC = "AIC")
mlg.AIC$BestModel
```
###Choix du sous modéle.
#### Comparaison du modèle complet avec le modèle AIC


```{r}
#
mlg_rg_best_aic <- glm(Energy.efficiency.bis~Relative.compactness + Overall.height+Glazing.area,family=binomial(link=logit),data=data.mlg)
anova(mlg_rg_best_aic,mlg_rg,test="Chisq")
```

La pvaleur obtenue étant de 0.003229  donc on rejette le modéle AIC au risque de 5%. 

#### Comparaison du modèle complet avec le modèle BIC
```{r}

# On note que le sous modèle bic est un sous modèle du modèle AIC
#### Comparaison du modèle AIC  avec le sous modèle BIC
mlg_rg_best_bic <- glm(Energy.efficiency.bis~Relative.compactness + Glazing.area + 
    Overall.height + Glazing.area.distr,family=binomial(link=logit),data=data.mlg)
summary(mlg_rg_best_bic)
anova(mlg_rg_best_bic,mlg_rg,test="Chisq")
```
La pvaleur obtenue étant de 0.5543 on retient le modèle BIC au risque 5%

## Modèle avec intéraction
Regardons si le modèle avec intéraction définit mieux le problème de regression.
```{r}
#Ajustement du modèle complet avec intéraction 
mlg_rg_inter <- glm(Energy.efficiency.bis~Relative.compactness + 
    Surface.area + Wall.area + Overall.height + orientation + 
    Glazing.area + Glazing.area.distr + Surface.area:Relative.compactness+Wall.area:Glazing.area +Surface.area:Wall.area,data=data.mlg,family=binomial(link="logit"))
summary(mlg_rg_inter)
```

### Calcul du pseudo R2
```{r}
#Calcul de pseudo R2
pseudoR2 = 1 - ( mlg_rg_inter$deviance/mlg_rg_inter$null.deviance)
print("Pseudo R2 ")
print(pseudoR2)
```
Le pseudo R2 obtenu est de 0.7796646 (contre  0.712583 pour le modèle additif).

### Recherche de sous modèle
```{r}
modelbestinter = step(mlg_rg_inter,trace = FALSE)
summary(modelbestinter)
```
### Comparaison du modèle complet avec le sous modèle trouvé par la méthode du step
```{r}

mlg_inter_best_aic <- glm(Energy.efficiency.bis ~ Relative.compactness + Surface.area + 
    Wall.area + Overall.height + orientation + Glazing.area + 
    Glazing.area.distr + Surface.area:Wall.area,family=binomial(link=logit),data=data.mlg)
summary(mlg_inter_best_aic)
anova(mlg_inter_best_aic,mlg_rg_inter,test="Chisq")
```

La pvaleur étant de 0.9577 on ne rejette donc pas H0
ON conserve le sous  modèle AIC
## Choix du meilleur sous modèle
Comparaison du modèle AIC sans intéraction avec le modèle AIC avec intéraction 
Dans ce cas précis les modèle sans intéraction est un sous modèle de celui avec intéraction donc
on peut réaliser un test de sous modèle
```{r}
anova(mlg_rg_best_aic,mlg_inter_best_aic,test="Chisq")
```

La pvaleur étant de 0.006016 on rejette H0
Donc on conserve mlg_inter_best_aic.

## Regression polytomique pour la variable Energy.efficiency
###  Mise en forme du jeu de données utilisées
Dans la mise en forme du jeu de données, la variable Energie et Roof.Area ont été supprimées. En raison du fait que,
d'une part les variables Surface.area, Wall.area et la Roof.area sont liées, et d'aute part la variable de sortie 
ici considérée est Energy.efficiency.
```{r}
data.mlg.p<-new_data[,c(-4,-9)]
```
### Statistique descriptive 
```{r}
#Statistique Descriptive
boxplot(Relative.compactness~ Energy.efficiency,data=data.mlg.p)
boxplot(Surface.area~ Energy.efficiency,data=data.mlg.p)
boxplot(Wall.area~ Energy.efficiency,data=data.mlg.p)
boxplot(Overall.height~ Energy.efficiency,data=data.mlg.p)
boxplot(Glazing.area~ Energy.efficiency,data=data.mlg.p)
mosaicplot(table(data.mlg.p[,c("Energy.efficiency","orientation")]))
``` 
L'analyse des figures obtenues nous permet de noter que :
  * Les classes d'energies A,B,C ont une faible relative compactness par rapport aux classes D,E,F,G
  * Les classes d'energies A,B,C ont une grande Surface.area par rapport aux classes D,E,F,G
  * Les classes d'energies B,D,E,F ont en moyenne la même surface de Wall.area, mais pas la même distribution
    La classe A a une faible surface de Wall.area et la classe G en a une grande
  * Les classes d'energies A,B,C ont une faible Overall.height par rapport aux classes D,E,F,G

## Modèle linéaire généralisé polytomique additif
L'analyse statistique nous a permis d'identifier que toutes les variables avaient des effets sur l'Energy.efficiency
donc nous allons considérer le modèle additif.
Nous allons considérer les niveaux comme ordonnées pour notre analyse.
```{r}
# transformation en variable ordinale
data.mlg.p$Energy.efficiency = factor(data.mlg.p$Energy.efficiency, order = TRUE, levels = c("A", "B", 
    "C", "D","E","F","G"))
```

### Ajustement du modèle.
```{r}
modelord <- vglm(Energy.efficiency ~ Relative.compactness, data = data.mlg.p, family = acat())
```

# Non-linear models

## Classification

```{r}
prct_bien_classe=function(table){
      a =(table[1]+table[4])/sum(table)
    return(a) 
}
```

```{r}
data.nlm.class = data.mlg

# On sépare les données en un ensemble d'apprentissage et un ensemble de test
nb_train <- floor(0.75 * nrow(data.nlm.class))
train_ind <- sample(seq_len(nrow(data.nlm.class)), size = nb_train)

train <- data.nlm.class[train_ind, ]
test <- data.nlm.class[-train_ind, ]
```

```{r}
hatY = (mlg_rg$fitted.values > 0.5)
# table de contingences pour la régression logistique
t_reg_log = table(data.mlg[-train_ind,]$Energy.efficiency.bis, hatY[-train_ind])
t_reg_log
```
```{r}
pct_reg_log = prct_bien_classe(t_reg_log)
pct_reg_log
```

```{r}
library(rpart) # chargement de la librairie
library(rpart.plot)
tree.dis=rpart(Energy.efficiency.bis~.,data=train, parms = list(split = "information"),cp=0.001)
rpart.plot(tree.dis)
```

```{r}
pred.tree <- predict(tree.dis,newdata=test,type="class")
t_class_dis = table(pred.tree, test[, "Energy.efficiency.bis"])
t_class_dis
```
```{r}
pct_class_dis = prct_bien_classe(t_class_dis)
pct_class_dis
```

```{r}
xmat <- xpred.rpart(tree.dis)

# Comparaison des valeurs prédite et observée
xerr <- (train$Energy.efficiency.bis != 0) != (xmat > 1.5) 
# Calcul  des estimations des taux d'erreur
CVerr <- apply(xerr, 2, sum)/nrow(xerr)
cpMin <- as.numeric(attributes(which.min(CVerr))$names)
tree.dis.opti <- rpart(Energy.efficiency.bis~., data = train, parms = list(split = "information"), cp = cpMin)
rpart.plot(tree.dis.opti)
```

```{r}
pred.tree.opti <- predict(tree.dis,newdata=test,type="class")
t_class_dis = table(pred.tree.opti, test[, "Energy.efficiency.bis"])
```
```{r}
pct_class_dis = prct_bien_classe(t_class_dis)
pct_class_dis
```

```{r}
library(randomForest)
rf.dis <- randomForest(Energy.efficiency.bis ~ ., data = train[,c(-4,-7)], 
                       xtest = test[, c(-4,-7,-8)], ytest = test[, "Energy.efficiency.bis"],
                       ntree = 500, do.trace = 50, importance = TRUE)
```

```{r}
pred.rf <- rf.dis$test$predicted
table(pred.rf, test[,"Energy.efficiency.bis"])
```

```{r}
library(caret)
cvControl <- trainControl(method = "cv", number = 10)
rfFit <- train(train[, -8], train[, 8], method = "rf", tuneLength = 8,
               trControl = cvControl, trace = FALSE)

rf.dis.opti <- randomForest(Energy.efficiency.bis ~ ., data = train[,c(-4,-7)], 
                       xtest = test[, c(-4,-7,-8)], ytest = test[, "Energy.efficiency.bis"],
                       ntree = 500, do.trace = 50, importance = TRUE,mtry=as.integer(rfFit$bestTune))
pred.rf.opti <- rf.dis.opti$test$predicted
t_arbre = table(pred.rf.opti, test[,"Energy.efficiency.bis"])
pct_arbre = prct_bien_classe(t_arbre)
t_arbre
```

## Régression

### Mise en forme des données tests et apprentissage.
```{r}
data.nlm.reg = new_data[,c(-4,-10)]

# On sépare les données en un ensemble d'apprentissage et un ensemble de test
nb_train <- floor(0.75 * nrow(data.nlm.reg))
train_ind <- sample(seq_len(nrow(data.nlm.reg)), size = nb_train)

train <- data.nlm.reg[train_ind, ]
test <- data.nlm.reg[-train_ind, ]
```

### Estimation de l'arbre de régression.
```{r}
library(rpart) # chargement de la librairie
library(rpart.plot)
tree.reg=rpart(Energy ~.,data=train, cp=0.001)
rpart.plot(tree.reg)
```


```{r}
plot(tree.reg)
text(tree.reg)
```

### Elagage de l'abre de régression.
```{r}
xmat <- xpred.rpart(tree.reg)
xerr <- (xmat-train[,"Energy"])^2
CVerr <- apply(xerr, 2, sum)
```

### Construction de l'arbre avec cp minimisant l'erreur
Pour cela, nous allons rechercher le cp qui minimiser l'erreur.
```{r}
cpMin <- as.numeric(attributes(which.min(CVerr))$names)
tree.reg <- rpart(Energy~., data = train, control = rpart.control(cp = cpMin))
#library(partykit)
#plot(as.party(tree.dis.reg), type = "simple")
```

### Construction de l'arbre prédit par régression sur l'ensemble test
```{r}
pred.treer <- predict(tree.reg,newdata=test)
```

### Table de contingences
```{r}
t_reg = table(pred.treer > 35, test[, "Energy"] > 35)
```
```{r}
pct_reg = prct_bien_classe(t_reg)
pct_reg
```