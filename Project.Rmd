---
title: "Projet de statistiques : prédiction de la consommation énergétique de bâtiments"
output:
  pdf_document:
    toc: true
    number_sections: true
    toc_depth: 3
    includes:
      in_header: reformat_paragraph.tex  # needed to be able to use 4th level headers
  html_document:
    df_print: paged
toc-title: "Sommaire"
geometry: margin=2cm
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center", results="hold", cache = TRUE, fig.dim=c(8,3))
library(ggfortify)
library(VGAM)
library(ROCR)
library(tidyverse)
library(ggplot2)
library(esquisse)
library(FactoMineR)
library(leaps)
library(MASS)
library(glmnet)
library(gridExtra)
library(bestglm)
library(plotly)
library(caret)
library(factoextra)
# function used to break lines in the pdf outputs
# https://stackoverflow.com/questions/24020617/textwrapping-long-string-in-knitr-output-rstudio
str_break = function(x, width = 80L) {
  n = nchar(x)
  if (n <= width) return(x)
  n1 = seq(1L, n, by = width)
  n2 = seq(width, n, by = width)
  if (n %% width != 0) n2 = c(n2, n)
  substring(x, n1, n2)
}
```

# Introduction et présentation du jeu de données

L'objectif de ce projet est de prédire la consommation énergétique de différents
bâtiments en fonction de certaines de leurs caractéristiques (forme, surface,
fenêtres, orientation...). Cette consommation d'énergie est exprimable sous forme
quantitative (numériquement) ou qualitative (en classes de A à G).

Nous commencerons par une première partie d'analyse naïve de notre jeu de données,
avant de rentrer plus en profondeur dans la construction de modèles de prédiction.

Les modèles que nous avons implémentés sont des modèles linéaires (classiques 
et généralisés), ainsi que des modèles non linéaires (classification hiérarchique, 
arbre optimal, forêts aléatoires).

Nous disposons pour notre étude d'un jeu de données de 768 bâtiments.
Pour chaque bâtiment, nous possédons les 10 caractéristiques suivantes :

* Quantitatives :
  + `Relative.compactness` : compacité relative à un cube de même volume ($RC = 6 \times V^{0.66} \times A^{-1}$ avec $V$ et $A$ respectivement le volume et l'aire totale du batiment : murs + toit + sol)
  + `Surface.area` : surface totale (sol + murs + toit)
  + `Wall.area` : surface de mur extérieurs
  + `Roof.area` : surface de toit
  + `Glazing.area` : Surface vitrée (en pourcentage de la surface au sol)
  + `Energy` : Énergie consommée
* Catégorielles :
  + `Overall.height` : hauteur du batiment (soit 3.5, soit 7 m)
  + `orientation` : orientation de la maison (Nord, Sud, Est, Ouest)
  + `Glazing.area.distr` : Distribution des vitres (uniforme, ou davantage d'un coté)
  + `Energy.efficiency` : Indicateur de l'énergie consommée (de A (meilleur) à G (pire))
  
On cherchera donc dans les prochaines parties à prédire les variables `Energy` et `Energy.efficiency`. 

# Analyse des données

Nous allons dans un premier temps réaliser quelques statistiques exploratoires sur toutes nos variables.

## Statistiques descriptives

```{r}
# Lecture jeu de données, mise sous forme de facteur et corrections
data = read.table("DataEnergy-Student.csv", header = TRUE, sep = ",")
data$Glazing.area.distr = as.factor(factor(data$Glazing.area.distr))
data$Energy.efficiency = as.factor(data$Energy.efficiency)
data$orientation = as.factor(data$orientation)
data$Overall.height = factor(data$Overall.height, ordered = TRUE)
data$Glazing.area[which(data$Glazing.area.distr == 0)] = 0
# Informations sur le jeu de données
s = summary(data[,c(6,5,8,9,10)])
colnames(s)[5] = "Energy.eff" ; s
# Séparation des variables quantitatives et qualitatives
quanti = c(1, 2, 3, 4, 7, 9) ; quali = c(5, 6, 8, 10) ; allvariables = 1:10
```

On peut noter qu'il y a
le même nombre de bâtiments pour chaque orientation et pour chaque hauteur.
La distribution des fenêtres est aussi répartie équitablement entre les bâtiments,
sauf pour ceux sans fenêtres (modalité 0) qui sont moins nombreux.

L'énergie consommée s'étale de 10 à 95, avec une moyenne de 46. Les bâtiment avec
une faible consommation d'énergie (A ou B) sont assez nombreux (41\% des bâtiments).

```{r, fig.dim=c(8,4)}
par(mfrow=c(1,2))
plot(2*data$Roof.area + data$Wall.area, data$Surface.area, pch='.',
     main = "Relation entre les surfaces",
     xlab = "2 * Surface de toit + Surface murée",
     ylab = "Surface totale")
plot(1/(data$Surface.area), data$Relative.compactness, pch='.',
     main = "Relation entre compacité et surface",
     xlab = "Inverse de la surface totale",
     ylab = "Compacité relative")
```

La premier graphe nous montre que les variables `Roof.area`, `Wall.area` et `Surface.area` sont liées par la relation :
$\texttt{Surface.area} = 2 \times \texttt{Roof.area} + \texttt{Wall.area}$.
Ainsi, nous n'étudierons pas la variable `Roof.area` plus en détails par la suite, étant donnée
qu'elle peut être directement obtenue depuis d'autres variables.
<!-- Virer variable Roof.area ? -->

On observe sur le second graphe une relation linéaire entre la compacité relative et l'inverse de la surface totale. Ça n'est pas étonnant au vu de la formule de la compacité relative : $RC = 6 \times V^{0.66} \times A^{-1}$. Cependant, ici la relation linéaire n'est pas exacte comme dans le cas précédent : il y a potentiellement de l'information contenue dans les deux variables. Nous n'en écarterons donc pas une pour notre étude.

Nous avons également essayé de voir quelles étaient les variables les plus influentes sur l'énergie consommée.

```{r, fig.dim=c(8,4.5)}
par(mfrow = c(2,2), mar = c(4,4,2,1))
plot(Energy ~ Relative.compactness, data = data, pch = '.')
plot(Energy ~ Surface.area, data = data, pch = '.')
plot(Energy ~ Wall.area, data = data, pch = '.')
boxplot(Energy ~ Overall.height, data = data, pch = '.')
```

On voit que les variables liées à la forme du bâtiment jouent un rôle important
dans la consommation d'énergie. Ainsi, les bâtiments les moins consommateurs sont
ceux qui sont : moins hauts, plus compacts, de surface totale plus importante,
et de surface murée plus faible.

```{r, fig.dim=c(8,4.5)}
layout(matrix(c(1,2,3,2), 2, 2, byrow = TRUE))
par(mar = c(4,4,2,1))
boxplot(Energy ~ orientation, data = data)
plot(Energy ~ Glazing.area, data = data)
boxplot(Energy ~ Glazing.area.distr, data = data)
```

On voit ici que l'orientation ne semble pas avoir d'influence sur l'énergie consommée.

Pour la surface vitrée, on voit que les bâtiments sans vitres (modalité 0 de `Glazing.area.distr`
et valeur 0 de `Glazing.area`) consomment moins d'énergie que les bâtiments vitrés,comment on s'y attend.
En revanche, la distribution des vitres ne semble pas avoir de réel impact
(modalités 1 à 5 de `Glazing.area.distr`). Il semble cependant qu'il y ait une petite augmentation
de la consommation avec l'augmentation de la surface vitrée.

Afin d'étudier d'éventuelles corrélations entre nos variables, nous allons
maintenant mener une analyse en composantes principales.

## Analyse en Composantes Principales (ACP)

On souhaite réaliser une ACP afin de se ramener à un nombre de dimensions plus faible.
Nous allons pour cela utiliser le package `FactoMineR` qui contient toutes les
fonctions nécessaires à la réalisation de notre ACP.
On cherche d'abord combien d'axes principaux nous allons avoir besoin.

```{r, fig.dim=c(8,3.5)}
par(mfrow=c(1,2))
res.acp <- PCA(data,scale.unit=T,quali.sup=quali,quanti.sup=9,ncp=8, graph=F)
barplot(res.acp$eig[,"percentage of variance"], main="Pourcentage de variance",
        names.arg = seq(1,5), xlab = "Composantes principales")
barplot(res.acp$eig[,"cumulative percentage of variance"],
        main="Pourcentage de variance cumulée",
        names.arg = seq(1,5), xlab = "Composantes principales")
abline(h = 95, col = "red")
print(paste("Pourcentage d'inertie expliquée par les trois premiers axes :",
            res.acp$eig[,"cumulative percentage of variance"][3]))
```

On voit sur le premier graphe que l'inertie portée par les trois premiers axes principaux est prépondérante par rapport aux autres. Ils expliquent presque 99\% de l'inertie. Les deux premiers axes ne portent eux que 82\% de l'inertie. Ne choisir que deux axes effacerait trop d'informations. Nous allons donc poursuivre notre analyse sur les trois premiers axes principaux.

Les graphes des variables nous donnent des informations intéressantes sur les variables corrélées.

```{r, fig.dim=c(6,6)}
layout_matrix = matrix(c(1,2,3,3), 2, 2, byrow = TRUE)
gg1 = plot.PCA(res.acp, choix="var", axes = c(1,2), new.plot = F,title = "Variables (axes 1/2)")
gg2 = plot.PCA(res.acp, choix="var", axes = c(1,3), new.plot = F,title = "Variables (axes 1/3)")
gg3 = plot.PCA(res.acp, choix="var", axes = c(2,3), new.plot = F,title = "Variables (axes 2/3)")
grid.arrange(gg1,gg2,gg3,layout_matrix=layout_matrix)
```

Les variables `Relative.compactness`, `Surface.area` et `Roof.area` semblent être plutôt portées par le premier axe principal (en positif pour les deux premières, négatif pour les deux autres).

Le second axe porte principalement la variable `Wall.area`, et le troisième la variable `Glazing.area`.

Finalement, les deux premiers axes ont plutôt trait à la forme du bâtiment (surface au sol pour le premier et surface murée pour le second), tandis que le troisième axe correspond à la surface vitrée.

Ainsi, l'énergie dépensée dépend d'abord de la forme du bâtiment, et ensuite de la surface vitrée.

Nous pouvons également observer les graphes des individus. Nous représentons les différentes classes énergétiques par couleur.


```{r, fig.dim=c(7,4)}
gg1 = plot(res.acp,choix="ind",axes = c(1,2),invisible="quali",habillage="Energy.efficiency",
           label="none", new.plot=F) + theme(text=element_text(size=8),legend.position="none")
gg2 = plot(res.acp, choix="ind", axes = c(2,3), invisible="quali",habillage="Energy.efficiency",
           label="none", new.plot=F) + theme(text=element_text(size=8), legend.position="none")
gg3 = plot(res.acp, choix="ind",axes = c(1,3),invisible="quali",habillage="Energy.efficiency",
           label="none", new.plot=F) + theme(text=element_text(size=8)) +
  guides(color=guide_legend(ncol=2))
grid.arrange(gg1,gg2,gg3,layout_matrix = layout_matrix)
```

On peut voir sur le premier et le troisième graphique que l'axe 1 marque une claire séparation entre les classes A, B, C et les classes D, E, F, G.

Les bâtiments à la consommation énergétique la plus faible possèdent des coordonnées négatives pour la première composante. Ils sont plus bas et plus compacts, comme on peut le voir sur les graphiques suivants :

```{r, fig.dim=c(7,4)}
gg1 = plot(res.acp,choix="ind",axes = c(1,2),invisible="quali",habillage="Relative.compactness",
           label = "none", new.plot = FALSE) + theme(text = element_text(size=8))
gg2 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="Overall.height",
           label = "none", new.plot = FALSE) + theme(text = element_text(size=8))
gg3 = plot(res.acp, choix="ind", axes = c(1,3), invisible="quali", habillage="Glazing.area.distr",
           label = "none", new.plot = FALSE) + theme(text = element_text(size=5))
grid.arrange(gg1,gg2,gg3,layout_matrix=layout_matrix)
```

Ainsi, les maisons plus étalées sur le sol possèdent les meilleures performances énergétiques.

<!-- INTERPRETATION -->

## Clustering de variables

Nous allons essayer de voir si nous pouvons classer nos variables en différents
groupes qui nous permettraient de prédire leur consommation énergétique.

### Analyse visuelle

Nous menons d'abord une analyse visuelle au sein de nos différentes variables 
afin de mettre en évidence de potentiels groupes.

```{r, fig.dim=c(6,3)}
gg1 = ggplot(data) + aes(x = Relative.compactness, y = Energy) +
  geom_point() + theme_minimal()
gg2 = ggplot(data) + aes(x = Glazing.area, y = Energy) +
  geom_point() + theme_minimal()
grid.arrange(gg1,gg2,ncol=2)
```

Visuellement, c'est selon la compacité relative et la surface vitrée que l'on distingue le mieux des groupes.

Avec la compacité relative, on constate principalement deux groupes. On peut également voir 12 groupes mais ceux-ci sont moins évidents.

Avec la surface vitrée, on distingue principalement quatre groupes avec deux sous-groupes
à chaque fois.

### Clustering hiérarchique

Après cette analyse visuelle, nous allons utiliser des méthodes de clustering pour confirmer ou infirmer nos observations. Commençons par le clustering hiérarchique.

<!-- POURQUOI LIGNES ROUGES ? -->

```{r, fig.dim=c(6,3.5), fig.show='hold'}
par(mfrow=c(1,2), mar = c(4,4,2,1))
hc = hclust(dist(data[c(1,2,3,4,5,7)]), method = "ward.D2")
plot(hc, xlab = "")
abline(h=c(3400,1300,880,200),col="red")
plot(sort(hc$height, decreasing = TRUE)[1:20], ylab = "Height")
abline(v=c(1.5,3.5,4.5,11.5),col="red")
```
Sur le dendogramme, deux classes apparaissent clairement. On peut aussi distinguer 4,5 ou 12 classes.
Sur le graphique de la variance inter-classe, on observe un saut important au passage à 2 classes. On retrouve également les résultats que l'on a obtenu avec le dendogramme en observant des sauts aux passages à 4, 5 et 12 classes.

Ces premiers outils semblent confirmer les nombres de classes qui semblent pertinents : 2, 4 et 12.

On réalise donc dans un premier temps un découpage en 2, 4 et 12 classes selon le clustering hiérarchique. On superpose ensuite ces classes sur nos graphes précédents.

```{r, fig.height=2.5}
class2 = cutree(hc, k = 2)   # clustering hiérarchique à 2 classes
class4 = cutree(hc, k = 4)   # clustering hiérarchique à 4 classes
class12 = cutree(hc, k = 12) # clustering hiérarchique à 12 classes
gg1 = ggplot(data) + aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class2) + theme_minimal()
gg2 = ggplot(data) + aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class4) + theme_minimal()
gg3 = ggplot(data) + aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class12) + theme_minimal()
grid.arrange(gg1,gg2,gg3,ncol=3)
```

En regardant la compacité relative, les découpages en 2 et 12 classes semblent très pertinents. Celui en 4 classe l'est moins. On peut un peu mieux voir la séparation des 4 classes en regardant la surface murée ci-dessous. On aurait tout de même envie de découper en plus de classes dans ce graphique.

```{r, fig.dim=c(3.5,2.3)}
ggplot(data) + aes(x = Wall.area, y = Energy) +
 geom_point(size = 0.7, colour = class4) + theme_minimal()
```

Le découpage en 2 classes semble très marqué, nous aimerions savoir si il n'est pas lié à la seule variable à deux modalités de notre jeu de donnée : la hauteur du batiment.

```{r}
table(class2, data$Overall.height)
```

La table de contingence confirme bien notre intuition : les deux classes correspondent exactement aux deux hauteurs de bâtiments de notre jeu de données.

### k-means

On utilise à présent un nouvel outil : les k-means. Nous souhaitons le comparer
au clustering hiérarchique.

```{r}
set.seed(42)
kmres2 = kmeans(data[,c(1:5,7)], centers = 2) # k-means à 2 classes
table(kmres2$cluster, data$Overall.height)
```
Pour deux classes, les deux méthodes fournissent exactement la même découpe : selon la hauteur.

```{r, fig.height=2}
set.seed(42)
kmres4 = kmeans(data[,c(1:5,7)], centers = 4) # k-means à 4 classes
kmclus4 = kmres4$cluster
kmres12 = kmeans(data[,c(1:5,7)], centers = 12) # k-means à 12 classes
kmclus12 = kmres12$cluster
gg1 = ggplot(data) + aes(x = Wall.area, y = Energy) +
  geom_point(size = 0.5, aes(color = as.factor(kmclus4))) +
  stat_ellipse(aes(group = as.factor(class4))) +
  theme_minimal() + theme(legend.position = "none")
gg2 = ggplot(data) + aes(x = Relative.compactness, y = Energy) +
  geom_point(size = 0.5, aes(color = as.factor(kmclus12))) +
  stat_ellipse(aes(group = as.factor(class12))) +
  theme_minimal() + theme(legend.position = "none")
grid.arrange(gg1,gg2,ncol=2)
```

Ces deux graphes représentent les découpes obtenues par les k-means (points colorés) et par le clustering hiérarchique (ellipses noires) pour 4 et 12 classes, selon deux variables choisies pour bien représenter la découpe.

Après plusieurs exécutions pour 4 classes, les k-means ne donnent presque jamais les mêmes résultats que le clustering hiérarchique (ellipses noires). Les clusters semblent souvent un peu moins pertinents (par exemple le groupe en haut à droite classé avec le groupe du milieu, assez éloigné).

Pour 12 classes, ils donnent des résultats plus proches du clustering hiérarchique. Les séparations dépendent toutefois des exécutions, et semblent globalement un peu moins bien définies qu'avec le clustering hiérarchique.

### Visualisation des classes sur les axes de l'ACP

On va essayer de projeter les classes obtenues par clustering sur l'ACP afin de voir si les découpages sont pertinents. Nous utilisons les classes obtenues par clustering hiérarchiques car celles-ci nous semblaient plus naturelles visuellement.

```{r, fig.height=2.8}
data_classes = data ; data_classes$class2 = as.factor(class2)
data_classes$class4 = as.factor(class4) ; data_classes$class12 = as.factor(class12)
res.acp_classes=PCA(data_classes,scale.unit=T,quali.sup=c(quali,11,12,13),quanti.sup=9,graph=F)
gg1 = fviz_pca_ind(res.acp_classes, c(1,2), habillage="class12", labels = F)
gg2 = fviz_pca_ind(res.acp_classes, c(1,3), habillage="class12", labels = F)
grid.arrange(gg1+theme(legend.position="none"),gg2+theme(legend.position="none"),ncol=2)
```

Les 12 groups sont visibles clairement sur l'ACP. Ils sont bien séparés selon le premier axe principal. Ainsi, les clusters sont principalement réalisés selon la forme du bâtiment (`Surface.area`, `Relative.compactness`, `Overall.height`).

# Modèles linéaires

## Modèle fonction des variables quantitatives

Nous étudierons dans un premier temps des modèles linéaires expliquant la variable quantitative `Energy` en fonction des variables *quantitatives* uniquement. Comme expliqué précedement, nous écartons `Roof.area` car elle rendrait notre modèle singulier.

### Modèle avec interactions

Nous construisons d'abord naïvement premier modèle contenant les variables quantitatives et leurs interactions.

<!-- QQ-PLOT ? -->

```{r, fig.dim=c(8,3)}
model_quanti_complet = lm(Energy ~ (. - Roof.area)^2, data = data[,quanti])
paste("R² =",summary(model_quanti_complet)$r.squared)
data$fitted_quanti_complet = model_quanti_complet$fitted.values
ggplot(data) + 
  aes(x = fitted_quanti_complet, y = Energy) +
  geom_point() + geom_abline(slope = 1) +
  labs(title = "Regression linéaire de `Energy` en fonction des variables quantitatives",
       x = "Valeurs ajustées") +
  theme_minimal()
```

Le modèle obtenu semble bien passer au sein des données : on trouve un $R^2$ de 0.8692.

Cependant, ce modèle conserve beaucoup de variables, on peut donc se demander si elles sont toutes pertinentes. Nous allons donc essayer ne n'en conserver que certaines.

### Selection de variables par critère BIC

Nous allons réaliser dans un premier temps une sélection de variables par critère BIC.

```{r}
modselect_quanti_bic_back = stepAIC(model_quanti_complet,trace=FALSE,
                                    direction=c("backward"),k=log(nrow(data)))
f = paste("Energy ~", paste(dimnames(modselect_quanti_bic_back$qr$qr)[[2]][-1], collapse=" + "))
str_break(f)  # pour autoriser des retours à la ligne dans la sortie
```

Le modèle selectionné conserve nos 5 des variables quantitatives, mais supprime certaines de de leur interactions. Afin de s'assurer que l'on peut simplifier notre modèle, on réalise un test de sous-modèle entre le modèle complet et le modèle selectionné.

```{r}
anova(modselect_quanti_bic_back, model_quanti_complet)
paste("R² =", summary(modselect_quanti_bic_back)$r.squared)
```

On obtient une p-valeur de 0.1477. On ne rejette donc pas notre modèle selectionné au seuil de 5 \%.
Ainsi, notre modèle réduit possède un $R^2$ de 0.8685, ce qui est à peine plus faible que ce que nous avions avec toutes nos variables (0.8692).

### Selection de variable par regression regularisée

On peut également tenter de sélectionner nos variables par régression régularisée.
Nous nous contenterons d'étudier le modèle sans interactions car la fonction que nous utiliserons ne traite pas de priorisation entre les effets principaux et les interactions.

```{r}
# centrage et reduction des données
energy = scale(data["Energy"],center=T,scale=T)
expli = scale(data[quanti[-6]],center=T,scale=T)
# création du tableau de tau
tau_seq <- seq(0, 0.1, by = 0.0001)
```


#### Ridge

```{r, eval=FALSE, include=F}
fitridge <- glmnet(x = expli, y = energy, family = "gaussian", alpha = 0, lambda = tau_seq, intercept = F)

# récupération du tau minimum par validation croisée
ridge_cv = cv.glmnet(x = expli, y = energy, family = "gaussian", alpha = 0, lambda = tau_seq, intercept = F)
tau_min_ridge = ridge_cv$lambda.min
print(tau_min_ridge)

# affichage des estimations de tau
dfridge=data.frame(tau = rep(fitridge$lambda,ncol(expli)),
                   theta=as.vector(t(fitridge$beta)),
                   variable=rep(colnames(expli),each=length(fitridge$lambda)))
ggplot(dfridge,aes(x=tau,y=theta,col=variable)) +
  geom_line() +
  geom_vline(xintercept = tau_min_ridge, linetype = "dotted", color = "red") +
  theme(legend.position="right")
```

```{r, eval=FALSE, include=F}
# illustration de la meilleure valeur de tau
df2=data.frame(tau=ridge_cv$lambda,MSE=ridge_cv$cvm,cvup=ridge_cv$cvup,cvlo=ridge_cv$cvlo)
ggplot(df2)+
  geom_line(aes(x=tau,y=MSE))+
  geom_vline(xintercept = tau_min_ridge,col="red",linetype="dotted")+
  geom_line(aes(x=tau,y=cvup),col="blue",linetype="dotted")+
  geom_line(aes(x=tau,y=cvlo),col="blue",linetype="dotted")
```

Nous avons vu que la régression Ridge ne nous donnait pas de résultats très intéressants, il était difficile de voir clairement quelles variables écarter. Nous ne nous attarderons donc pas plus en détails dessus, et nous allons essayer une régression lasso, qui permet d'écarter plus facilement des variables.

#### Lasso

```{r}
fitlasso <- glmnet(x = expli, y = energy, family = "gaussian", alpha = 1,
                   lambda = tau_seq, intercept = F)
dflasso=data.frame(tau = rep(fitlasso$lambda,ncol(expli)), theta=as.vector(t(fitlasso$beta)),
                   variable=rep(colnames(expli), each=length(fitlasso$lambda)))
ggplot(dflasso,aes(x=tau,y=theta,col=variable)) +
  geom_line() +
  geom_vline(xintercept = 0.02, linetype = "dotted", color = "red") +
  theme(legend.position="right")
```

```{r, eval=FALSE, include=F}
# récupération du tau minimum par validation croisée
lasso_cv = cv.glmnet(x = expli, y = energy, family = "gaussian", alpha = 1, lambda = tau_seq, intercept = F)
tau_min_lasso = lasso_cv$lambda.min
print(tau_min_lasso)
# illustration de la meilleure valeur de tau
df3=data.frame(tau=lasso_cv$lambda,MSE=lasso_cv$cvm,cvup=lasso_cv$cvup,cvlo=lasso_cv$cvlo)
ggplot(df3)+
  geom_line(aes(x=tau,y=MSE))+
  geom_vline(xintercept = tau_min_lasso,col="red",linetype="dotted")+
  geom_line(aes(x=tau,y=cvup),col="blue",linetype="dotted")+
  geom_line(aes(x=tau,y=cvlo),col="blue",linetype="dotted")
```

Certains variables s'écrasent bien à 0. En choisissant un seuil de 0.02, la régularisation écarterait les variables `Surface.area` et `Relative.compactness` (comme nous avons vu dans la partie 1, ces deux variables sont très liées). Cependant ce seuil est arbitraire. En essayant de le choisir par validation croisée pour minimiser le critère MSE, nous trouvons 0. Nous devrions donc conserver toutes nos variables. Cela serait cohérent avec les résultats de la sélection par critère BIC, qui conservait toutes les variables (plus certaines interactions). Le fait de ne pas pouvoir tester les interactions nous limite sur les conclusions que nous pouvons tirer des régressions régularisées.

Ainsi le modèle issu de la sélection BIC semble un bon premier candidat pour notre modèle final. Cependant, nous n'avons traité pour le moment que des variables quantitatives. Nous allons donc maintenant essayer de voir si les variables qualitatives de notre jeu de données ne pourraient pas nous apporter des informations supplémentaires.

## Modèle dépendant de toutes les variables

On construit un modèle complet avec interactions, et on teste un sous-modèle sans interactions pour voir si on pourrait s'en passer.

```{r}
model_complet = lm(Energy ~ (. - Roof.area)^2, data = data[,allvariables[-10]])
data$fitted_complet = model_complet$fitted.values
model_no_interactions = lm(Energy ~ . - Roof.area, data = data[,allvariables[-10]])
anova(model_complet, model_no_interactions)
```

La p-valeur est très faible : on doit conserver des interactions. De la même manière que précédemment, nous allons essayer un algorithme de sélection de variables par critère BIC pour faire le tri dans ce qui est utile ou pas.

```{r}
modselect_bic_back=stepAIC(model_complet,trace=FALSE,direction=c("backward"),k=log(nrow(data)))
f = paste("Energy ~", paste(dimnames(modselect_bic_back$qr$qr)[[2]][-1], collapse=" + "))
str_break(f)
```

Ainsi la sélection laisse complètement de côté la variable `orientation`, et supprime également certaines interactions. D'après notre analyse exploratoire en première partie, le retrait de cette variable n'est pas étonnant : elle semblait n'avoir aucun impact sur la consommation d'énergie.

On réalise un test de sous-modèle afin de vérifier que nous pouvons bien simplifier le modèle complet.

```{r}
anova(modselect_bic_back, model_complet)
```

On obtient une p-valeur supérieure à 99\%, on ne rejette donc pas le modèle réduit.

Ainsi, le modèle linéaire final que nous conservons est de la forme :
$$
\begin{aligned}
  Energy_i &= \theta_0 + \theta_1 Relative.compactness_i + \theta_2Surface.area_i + \theta_3 Wall.area_i \\
  &+ \theta_4 \mathbb{I}_{Overall.height_i = 7} + \theta_5 Glazing.area_i \\
  &+ \theta_{6,1} \mathbb{I}_{Glazing.area.distr_i = 1} + \theta_{6,2} \mathbb{I}_{Glazing.area.distr_i = 2} + \theta_{6,3} \mathbb{I}_{Glazing.area.distr_i = 3} \\
  &+ \theta_{6,4} \mathbb{I}_{Glazing.area.distr_i = 4} + \theta_{6,5} \mathbb{I}_{Glazing.area.distr_i = 5} \\
  &+ \gamma_1 Relative.compactness_i \times Surface.area_i + \gamma_2 Relative.compactness_i \times Wall.area_i \\
  &+ \gamma_3 Relative.compactness_i \times \mathbb{I}_{Overall.height_i = 7} + \gamma_4 Relative.compactness_i \times Glazing.area_i \\
  &+ \gamma_5 Surface.area_i \times \mathbb{I}_{Overall.height_i = 7} + \gamma_6 Wall.area_i \times \mathbb{I}_{Overall.height_i = 7} \\
  &+ \gamma_7 Wall.area_i \times Glazing.area_i + \varepsilon_i
\end{aligned}
$$

avec $\varepsilon_i \sim \mathcal{N}(0,\sigma^2)$. Pour vérifier cette dernière condition, on peut tracer les graphes des résidus :

```{r}
par(mfrow=c(1,2)) ; plot(modselect_bic_back, which=c(1,2), pch="+", cex=0.6)
```

Les graphes ne semblent pas trop mal, il semble toutefois que la variance des résidus correspondant aux hautes valeurs ajustées sont plus élevé que celle des plus faibles. Il y a également un décrochage du QQ-plot en bas à gauche. Ces résultats laissent penser que l'hypothèse de la normalité des résidus n'est pas vraiment vérifiée. Nous allons tout de même tester le pouvoir de prédiction de ce modèle, puis nous essaierons une approche par modèle linéaire généralisé pour voir si nous trouvons de meilleur résultats.

## Pouvoir de prédiction du modèle

Maintenant qu'on a déterminé les variables d'intérêt, nous allons tester le pouvoir de prédiction de notre modèle. Pour cela, nous allons faire de la validation croisée. 

```{r}
set.seed(42)
train.control = trainControl(method = "cv", number = 10, p = 0.8)
model_cv = train(modselect_bic_back$terms, data = data, method = "lm", trControl = train.control)
print(model_cv)
```

On obtient un $R^2$ de presque 90\%, le modèle passe donc bien par les données. De plus, l'erreur moyenne absolue de moins de 5. En sachant que la variable `Energy` s'étale de 10 à 95, notre erreur est assez faible : elle représente moins de 6\% de l'étendue de nos données.

# Modèle linéaire généralisée

Nous allons maintenant essayer de prédire l'énergie consommée en utilisant les labels énergétique plutôt que la valeur numérique. Nous allons donc utiliser des modèles linéaires généralisés.

### Mise en forme des données

Nous allons dans un premier temps séparer notre variable `Energy.efficiency` en deux classes (A/B ou C/D/E/F/G) que nous stockerons dans la varibale `Energy.efficiency.bis`.

```{r, echo = F}
new_data <- data[,allvariables]
data.mlg = data.frame(new_data[,-c(4,9,10)], Energy.efficiency.bis = rep(0, nrow(new_data)))
data.mlg$Energy.efficiency.bis[which(is.element(data$Energy.efficiency, c("A","B")))]="1"
data.mlg$Energy.efficiency.bis[which(!is.element(data$Energy.efficiency, c("A","B")))]="0"
data.mlg$Energy.efficiency.bis = as.factor(data.mlg$Energy.efficiency.bis)
```

### Statistique descriptive 

```{r, fig.dim=c(8,4), echo=F}
par(mfrow=c(2,2), mai=c(1,1,0.1,0))
boxplot(Relative.compactness~Energy.efficiency.bis,data=data.mlg,ylab="Compacité")
boxplot(Surface.area~Energy.efficiency.bis,data=data.mlg)
boxplot(Wall.area~Energy.efficiency.bis,data=data.mlg)
mosaicplot(Energy.efficiency.bis~Overall.height,data=data.mlg,main=NULL)
```

Ainsi, les bâtiments à la meilleure consommation énergétique ont une compacité ont
une compacité relative faible, une surface totale élevée, une surface de murs faible et une hauteur faible.
    
## Modèle linéaire généralisé additif

Nous allons d'abord construire un modèle linéaire généralisé additif sans interactions à l'aide de la fonction `glm`.

```{r}
mlg <- glm(Energy.efficiency.bis~.,data=data.mlg,family=binomial(link="logit"))
# summary(mlg)
pseudoR2 = 1 - (mlg$deviance/mlg$null.deviance) ; print(paste("Pseudo R² :",pseudoR2))
```

On trouve un pseudo $R^2$ de 0.71, ce qui n'est pas trop mal. Nous allons voir si nous pouvons le simplifier en recherchant un sous-modèle. Pour allons réaliser des sélections par critères BIC et AIC à l'aide de la fonction `bestglm`.

### Recherche de sous modèle

```{r, echo=F, eval=T, warning=F, message=F}
print("############################  BIC  #############################")
mlg.BIC <- bestglm(data.mlg, family = binomial, IC = "BIC")
mlg.BIC$BestModel
print('')
print("############################  AIC  #############################")
mlg.AIC <- bestglm(data.mlg, family = binomial, IC = "AIC")
mlg.AIC$BestModel
```

Les sélections par chacun des critères nous donnent des modèles assez différents. Ils sont cependant d'accord pour écarter les variables `Surface.area`, `Wall.area` et `orientation`. Pour choisir, nous allons réaliser un test de sous-modèle par rapport au modèle complet.

#### Test du sous-modèle BIC

```{r, echo=F, eval=T}
mlg_best_bic <- glm(Energy.efficiency.bis ~ Relative.compactness + Overall.height + Glazing.area, family = binomial(link = "logit"), data = data.mlg)
anova(mlg_best_bic,mlg,test="Chisq")
```

La p-valeur obtenue étant de 0.003229, donc on rejette le sous modèle AIC au risque de 1\%.

#### Test du sous-modèle AIC
```{r, echo=F, eval=T}
mlg_best_aic <- glm(Energy.efficiency.bis ~ Relative.compactness + Glazing.area + 
    Overall.height + Glazing.area.distr, family=binomial(link=logit), data=data.mlg)
anova(mlg_best_aic,mlg,test="Chisq")
```
La p-valeur obtenue étant de 0.5543 on retient le modèle AIC au risque 5\%.

#### Modèle sélectionné

Ainsi nous retenons le modèle AIC :
$$
\begin{aligned}
  Energy_i &= \theta_0 + \theta_1 Relative.compactness_i + \theta_2 Glazing.area_i \\
  &+ \theta_3 \mathbb{I}_{Overall.height_i = 7} \theta_{4,1} \mathbb{I}_{Glazing.area.distr_i = 1} + \\
  &+ \theta_{4,2} \mathbb{I}_{Glazing.area.distr_i = 2} + \theta_{4,3} \mathbb{I}_{Glazing.area.distr_i = 3} \\
  &+ \theta_{4,4} \mathbb{I}_{Glazing.area.distr_i = 4} + \theta_{4,5} \mathbb{I}_{Glazing.area.distr_i = 5}
\end{aligned}
$$

## Modèle avec interactions

Nous allons maintenant essayer de voir si les interactions ne nous apporteraient pas un meilleur modèle.
Nous ne considérerons que certaines interaction, étant donné que toutes les considérer causait des soucis dans la sélection de modèle plus tard.

```{r}
mlg_inter = glm(Energy.efficiency.bis~.+Relative.compactness:Surface.area+
                  Relative.compactness:Wall.area+Wall.area:Glazing.area+
                  Relative.compactness:Overall.height+Surface.area:Wall.area,
                data=data.mlg,family=binomial(link="logit"))
# summary(mlg_inter)
pseudoR2 = 1-(mlg_inter$deviance/mlg_inter$null.deviance) ; print(paste("Pseudo R² :",pseudoR2))
```
On obtient ainsi un pseudo $R^2$ de 0.720, ce qui est un peu plus élevé que pour le modèle complet (0.713). L'augmentation est cependant très faible, et l'ajout d'interaction est peut-être inutile.

On fait un test de sous-modèle afin de voir si le modèle sans interaction BIC précédent ne suffirait pas à expliquer nos données :

```{r}
anova(mlg_best_aic,mlg_inter,test="Chisq")
```

La p-valeur est de 0.28, on se contente donc du modèle sans interaction, au risque de 5\%.

## Regression polytomique pour la variable Energy.efficiency

###  Mise en forme du jeu de données utilisées

Nous souhaiterions maintenant prédire la variable `Energy.efficiency`, à 7 modalités.

```{r}
data.mlg.p<-new_data[,c(-4,-9)]
```
### Statistique descriptive 
```{r}
#Statistique Descriptive
boxplot(Relative.compactness~ Energy.efficiency,data=data.mlg.p)
boxplot(Surface.area~ Energy.efficiency,data=data.mlg.p)
boxplot(Wall.area~ Energy.efficiency,data=data.mlg.p)
boxplot(Overall.height~ Energy.efficiency,data=data.mlg.p)
boxplot(Glazing.area~ Energy.efficiency,data=data.mlg.p)
mosaicplot(table(data.mlg.p[,c("Energy.efficiency","orientation")]))
``` 
L'analyse des figures obtenues nous permet de noter que :
  * Les classes d'energies A,B,C ont une faible relative compactness par rapport aux classes D,E,F,G
  * Les classes d'energies A,B,C ont une grande Surface.area par rapport aux classes D,E,F,G
  * Les classes d'energies B,D,E,F ont en moyenne la même surface de Wall.area, mais pas la même distribution
    La classe A a une faible surface de Wall.area et la classe G en a une grande
  * Les classes d'energies A,B,C ont une faible Overall.height par rapport aux classes D,E,F,G

## Modèle linéaire généralisé polytomique additif

Nous allons considérer les niveaux comme ordonnées pour notre analyse, car dans notre cas les 
les classes ont une signification ordonnée.
```{r}
# transformation en variable ordinale
data.mlg.p$Energy.efficiency = factor(data.mlg.p$Energy.efficiency, order = TRUE, levels = c("A", "B", 
    "C", "D","E","F","G"))
```

### Ajustement du modèle.
L'analyse statistique nous a permis d'identifier que toutes les variables avaient des effets sur l'Energy.efficiency
donc nous devrions considérer le modèle additif avec toutes les autres variables. Cependant, en ajoutant la variable
Overall.height, la fonction ne parvient pas à faire l'ajustement, donc on ne va pas la considérer.

```{r}

modelord <- vglm(Energy.efficiency ~ Relative.compactness+ Glazing.area  + Glazing.area.distr, data = data.mlg.p, family = acat())
```

```{r}
#pseudoR2 = 1 - ( modelord$deviance/modelord$null.deviance)
```

# Non-linear models

```{r, echo=F}
prct_bien_classe=function(table){
      a =(table[1]+table[4])/sum(table)
    return(a) 
}
```

## Classification

### Préparation des données

```{r}
data.mlg$Overall.height = factor(data$Overall.height, ordered = FALSE)
data.nlm.class = data.mlg

ratio_train = 0.75

# On sépare les données en un ensemble d'apprentissage et un ensemble de test
nb_train <- floor(ratio_train * nrow(data.nlm.class))
train_ind <- sample(seq_len(nrow(data.nlm.class)), size = nb_train)

train.dis <- data.nlm.class[train_ind, ]
test.dis <- data.nlm.class[-train_ind, ]
```

### Régression logistique

```{r}
hatY = (mlg$fitted.values > 0.5)

# Table de contingences pour la régression logistique
t_reg_log = table(data.mlg[-train_ind,]$Energy.efficiency.bis, hatY[-train_ind])
t_reg_log
```
```{r}
# Pourcentage de valeurs correctement prédites
pct_reg_log = prct_bien_classe(t_reg_log)
pct_reg_log
```

### Arbre binaire de décision

#### Version naïve (``cp`` par défaut)
```{r, echo=F}
library(rpart) # chargement de la librairie
library(rpart.plot)
```

```{r}
tree.dis=rpart(Energy.efficiency.bis~.,data=train.dis, parms = list(split = "information"),cp=0.001)
rpart.plot(tree.dis)
```

```{r}
pred.tree <- predict(tree.dis,newdata=test.dis,type="class")
# Table de contingences pour l'arbre binaire de décision naïf
t_class_dis = table(pred.tree, test.dis[, "Energy.efficiency.bis"])
t_class_dis
```

```{r}
# Pourcentage de valeurs correctement prédites
pct_arb_nai_dis = prct_bien_classe(t_class_dis)
pct_arb_nai_dis
```

#### Version optimale

```{r}
# Optimisation de cp
xmat <- xpred.rpart(tree.dis)

# Comparaison des valeurs prédite et observée
xerr <- (train.dis$Energy.efficiency.bis != 0) != (xmat > 1.5) 
# Calcul  des estimations des taux d'erreur
CVerr <- apply(xerr, 2, sum)/nrow(xerr)
cpMin <- as.numeric(attributes(which.min(CVerr))$names)
tree.dis.opti <- rpart(Energy.efficiency.bis~., data = train.dis, parms = list(split = "information"), cp = cpMin)
rpart.plot(tree.dis.opti)
```

```{r}
pred.tree.opti <- predict(tree.dis,newdata=test.dis,type="class")
# Table de contingences pour l'arbre binaire de décision optimal
t_class_dis = table(pred.tree.opti, test.dis[, "Energy.efficiency.bis"])
t_class_dis
```
```{r}
# Pourcentage de valeurs correctement prédites
pct_arb_opti_dis = prct_bien_classe(t_class_dis)
pct_arb_opti_dis
```

### Random forest

```{r, echo=F}
library(randomForest)
```

#### Version naïve (``mtry`` par défaut)

```{r}
rf.dis <- randomForest(Energy.efficiency.bis ~ ., data = train.dis, 
                       xtest = test.dis[, -8], ytest = test.dis[, "Energy.efficiency.bis"],
                       ntree = 500, do.trace = 50, importance = TRUE)
```

```{r}
pred.rf <- rf.dis$test$predicted
# Table de contingences pour la random forest naïve
t_rdm_forest = table(pred.rf, test.dis[,"Energy.efficiency.bis"])
t_rdm_forest
```

```{r}
# Pourcentage de valeurs correctement prédites
pct_rdm_nai_dis = prct_bien_classe(t_rdm_forest)
pct_rdm_nai_dis
```


#### Version optimale

```{r}
# Optimisation de mtry
library(caret)
cvControl <- trainControl(method = "cv", number = 10)
rfFit <- train(train.dis[, -8], train.dis[, 8], method = "rf", tuneLength = 8,
               trControl = cvControl, trace = FALSE)

rf.dis.opti <- randomForest(Energy.efficiency.bis ~ ., data = train.dis, 
                       xtest = test.dis[,-8], ytest = test.dis[, "Energy.efficiency.bis"],
                       ntree = 500, do.trace = 50, importance = TRUE,mtry=as.integer(rfFit$bestTune))
```

```{r}
round(importance(rf.dis.opti),2)
```
```{r}

```
```{r}
pred.rf.opti <- rf.dis.opti$test$predicted
# Table de contingences pour la random forest naïve
t_rdm_forest_opti = table(pred.rf.opti, test.dis[,"Energy.efficiency.bis"])
t_rdm_forest_opti
```

```{r}
# Pourcentage de valeurs correctement prédites
pct_rdm_opti_dis = prct_bien_classe(t_rdm_forest_opti)
pct_rdm_opti_dis
```

## Régression

### Préparation des données

```{r}
new_data$Overall.height = factor(data$Overall.height, ordered = FALSE)
data.nlm.reg = new_data[,c(-4,-10)]

# On sépare les données en un ensemble d'apprentissage et un ensemble de test
nb_train <- floor(ratio_train * nrow(data.nlm.reg))
train_ind <- sample(seq_len(nrow(data.nlm.reg)), size = nb_train)

train.reg <- data.nlm.reg[train_ind, ]
test.reg <- data.nlm.reg[-train_ind, ]
```

### Arbre de régression 

```{r, echo=F}
library(rpart) # chargement de la librairie
library(rpart.plot)
```

#### Version naïve (``cp`` par défaut)

```{r}
tree.reg=rpart(Energy ~.,data=train.reg, cp=0.001)
rpart.plot(tree.reg)
```

```{r}
pred.tree <- predict(tree.reg,newdata=test.reg)
# Table de contingences pour l'arbre binaire de décision naïf
t_class_reg = table(pred.tree > 35, test.reg[, "Energy"] > 35)
t_class_reg
```

```{r}
# Pourcentage de valeurs correctement prédites
pct_arb_nai_reg = prct_bien_classe(t_class_reg)
pct_arb_nai_reg
```

#### Version optimale 

```{r}
xmat <- xpred.rpart(tree.reg)
xerr <- (xmat-train.reg[,"Energy"])^2
CVerr <- apply(xerr, 2, sum)/nrow(xerr)
```

```{r}
# On cherche la valeur de cp qui minimise l'erreur
cpMin <- as.numeric(attributes(which.min(CVerr))$names)
tree.reg <- rpart(Energy~., data = train.reg, control = rpart.control(cp = cpMin))
rpart.plot(tree.reg)
```

```{r}
pred.treer <- predict(tree.reg,newdata=test.reg)
# Table de contingences pour l'arbre binaire de décision naïf
t_reg = table(pred.treer > 35, test.reg[, "Energy"] > 35)
t_reg
```

```{r}
# Pourcentage de valeurs correctement prédites
pct_arb_opti_reg = prct_bien_classe(t_reg)
pct_arb_opti_reg
```


### Random forest

#### Version naïve (``mtry`` par défaut)

```{r}
rf.reg <- randomForest(Energy ~ ., data = train.reg, 
                       xtest = test.reg[, c(-8)], ytest = test.reg[, "Energy"],
                       ntree = 500, do.trace = 50, importance = TRUE)
```

```{r}
pred.rf <- rf.reg$test$predicted
# Table de contingences pour la random forest naïve
t_rdm_forest = table(pred.rf > 35., test.reg[,"Energy"] > 35.)
t_rdm_forest
```

```{r}
# Pourcentage de valeurs correctement prédites
pct_rdm_nai_reg = prct_bien_classe(t_rdm_forest)
pct_rdm_nai_reg
```


#### Version optimale

```{r}
# Optimisation de mtry
library(caret)
cvControl <- trainControl(method = "cv", number = 10)
rfFit <- train(train.reg[, -8], train.reg[, 8], method = "rf", tuneLength = 8,
               trControl = cvControl, trace = FALSE)

rf.reg.opti <- randomForest(Energy ~ ., data = train.reg, 
                       xtest = test.reg[, c(-8)], ytest = test.reg[, "Energy"],
                       ntree = 500, do.trace = 50, importance = TRUE,mtry=as.integer(rfFit$bestTune))
```

```{r}
pred.rf.opti <- rf.reg.opti$test$predicted
# Table de contingences pour la random forest naïve
t_rdm_forest_opti = table(pred.rf.opti > 35., test.reg[,"Energy"] > 35.)
t_rdm_forest_opti
```

```{r}
# Pourcentage de valeurs correctement prédites
pct_rdm_opti_reg = prct_bien_classe(t_rdm_forest_opti)
pct_rdm_opti_reg
```

## Tableau récapitulatif

```{r}
df.summarize = data.frame(
  classification = c(pct_reg_log,pct_arb_opti_dis,pct_rdm_opti_dis),
  regression = c(pct_reg_log,pct_arb_opti_reg,pct_rdm_opti_reg)
)
row.names(df.summarize) <- c("Regression logisitque", "Arbre optimal", "Random forest")
df.summarize
```

## Comparaison classification directe et régression à seuil

On a cherché à répartir les données en deux classes :
* ``Energy.efficiency = A,B`` (ou ``Energy <= 35`` )
* ``Energy.efficiency = C,D,E,F,G`` (ou ``Energy > 35``)

On remarque que les résultats obtenus par seuillage de la régression sont meilleurs. Ce résultat semble cohérent étant donné que l'apprentissage à partir des classes apporte moins d'informations que l'apprentissage à partir de la variable continue ``Energy``.

## Consistance des résultats avec l'analyse de données (partie 1)

On observe en effet la très bonne répartition des bâtiments en deux classes énergétiques (+ de 90% de bâtiments bien classés). Cela est cohérent avec les résultats obtenus en analyse de données. En effet, nous avions remarqué que le découpage en deux classes était très net. La décroissance de la variance inter-classe dans le cadre de la classification hiérarchique ascendante (méthode de Ward.D2) nous avait poussé à répartir les données en deux classes.

Dans le cadre de la régression logistique, les variables suivantes nous semblaient être les plus influentes : 

* Relative.compactness
* Glazing.area
* Overall.height
* Glazing.area.dist

Si l'on revient à l'analyse de données, et plus particulièrement à l'ACP, les variables suivantes contribuaient le plus : 

* Axe 1 (56%) : Relative.compactness, Surface.area, Roof.area. Sachant que Relative.compactness dépend de Surface.area et Roof.area, il est cohérent de ne retrouver que la Relative.compactness dans la sélection de variable.
* Axe 2 (23%) : Wall.area. Cette variable se retrouve également dans la Relative.compactness.
* Axe 3 (20%) : Glazing.area. Cette variable apporte une contribution relativement importante et n'est pas liée à la Relative.compactness, il est donc logique de la conserver.

On avait également remarqué que l'ACP différenciait bien les données selon leur Overall.height.
Quant à la Glazing.area.dist, nous n'avions pas remarqué d'influence particulière de cette variable.
