---
title: "Projet Stats"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center", results="hold")
library(ggfortify)
library(VGAM)
library(ROCR)
library(tidyverse)
library(ggplot2)
library(esquisse)
library(FactoMineR)
library(leaps)
library(MASS)
library(glmnet)
library(gridExtra)
library(bestglm)
```

# Analyse des données

## Statistiques descriptives

Le jeu de données est composé de 768 batiments. Pour chaque batiment, nous possédons les 10 variables suivantes :

C'est normal que la liste soit comme ça, c'est latex qui fait des listes correctes après.
* Quantitatives :
  + `Relative.compactness` : compacité relative à un cube de même volume ($RC = 6 \times V^{0.66} \times A^{-1}$ avec $V$ et $A$ respectivement le volume et l'aire totale du batiment (murs, toit, sol))
  + `Surface.area` : surface totale (sol + murs + toit)
  + `Wall.area` : surface de mur extérieurs
  + `Roof.area` : surface de toit
  + `Overall.height` : hauteur du batiment (soit 3.5 soit 7 m)
  + `Glazing.area` : Surface vitrée (en pourcentage de la surface au sol)
  + `Load` : Énergie consommée (quantité à prédire)
* Catégorielles :
  + `orientation` : orientation de la maison (Nord, Sud, Est, Ouest)
  + `Glazing.area.distr` : Distribution des vitres (uniforme, ou plus d'un coté)
  + `Energy.efficiency` : Indicateur de l'énergie consommées (de A (meilleur) à G (pire))

```{r}
# Lecture jeu de données
setwd("/home/leo/GoogleDrive/Cours/INSA_4A/Projet")
data = read.table("DataEnergy-Student.csv", header = TRUE, sep = ",")
# Mise sous forme de facteur des données catégorielles
data$Energy.efficiency = as.factor(data$Energy.efficiency)
data$Glazing.area.distr = as.factor(data$Glazing.area.distr)
data$orientation = as.factor(data$orientation)
# Correction du jeu de données
data$Glazing.area[which(data$Glazing.area.distr == 0)] = 0
# Informations sur le jeu de données
summary(data)
# Séparation des variables quantitatives et qualitatives
quanti = c(1:5, 7, 9)
quali = c(6, 8, 10)
```
La réalisation de la commande summary nous permet  de noter qu'il y'a 
le même nombre de batiments pour chaque oriention et aussi  le même 
nombre de répartition de fenêtre (sauf ceux qui n'en ont pas). 
```{r}
# pairs(data[, quanti], pch = '.', cex = 0.1, cex.labels = 0.55)
plot(2*data$Roof.area + data$Wall.area, data$Surface.area)
```
L'analyse de la courbe nous montre que les variables Roof.area, Wall.area et Surface.area sont liées par la relation  :2*Roof.area+Wall.area=Surface.area.


Même nombre de batiments faisant face à chaque orientation. Même nombre de batiments avec les différentes répartitions de fenêtres, sauf les batiments sans fenêtres.

```{r}
ggplot(data) +
 aes(x = Glazing.area, y = Energy, colour = as.factor(Overall.height)) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")
```

On voit que la surface vitrée à une influence sur l'énergie consommée.

```{r}
boxplot(Energy ~ Overall.height, data = data)
```
On voit que la variable Overall.height a une influence sur l'énergie consommée.
## Analyse en Composantes Principales (ACP)

On souhaite réaliser une ACP afin de mener une analyse en dimension plus faible. Nous allons pour cela utiliser le package 
`FactoMineR` qui contient toutes les fonctions nécessaires à la réalisation de notre ACP. On cherche d'abord combien d'axes principaux nous allons avoir besoin.

```{r}
library("FactoMineR")
par(mfrow=c(1,2))
res.acp <- PCA(data,scale.unit=T,quali.sup=c(6,8,10),quanti.sup=9,ncp=8, graph=F)
barplot(res.acp$eig[,"percentage of variance"], main="Pourcentage d'inertie",
        names.arg = seq(1,6), xlab = "Composantes principales")
barplot(res.acp$eig[,"cumulative percentage of variance"],
        main="Pourcentage d'inertie cumulé",
        names.arg = seq(1,6), xlab = "Composantes principales")
abline(h = 95, col = "red")
print(paste("Pourcentage d'inertie expliquée par les trois premiers axes :",
            res.acp$eig[,"cumulative percentage of variance"][3]))
```

On voit sur le premier graphe que l'inertie portée par les trois premiers axes principaux est prépondérante par rapport aux autres. D'après le graphe de pourcentage d'inertie cumulée, ils expliquent presque 99\% de l'inertie. Les deux premiers axes ne portent eux que 82\% de l'inertie. Ne choisir que deux axes effacerait trop d'informations. Nous allons donc poursuivre notre analyse sur les trois premiers axes principaux.

Les graphes des variables nous donnent des informations très intéressantes sur les variables corrélées.

```{r, fig.dim=c(6,6)}
gg1 = plot.PCA(res.acp, choix="var", axes = c(1,2), new.plot = FALSE,
               title = "Graphe des variables (axes 1 et 2)")
gg2 = plot.PCA(res.acp, choix="var", axes = c(1,3), new.plot = FALSE,
               title = "Graphe des variables (axes 1 et 3)")
gg3 = plot.PCA(res.acp, choix="var", axes = c(2,3), new.plot = FALSE,
               title = "Graphe des variables (axes 2 et 3)")
layout_matrix <- matrix(c(1, 1, 2, 2, 4, 3, 3, 4), nrow = 2, byrow = TRUE)
grid.arrange(gg1,gg2,gg3,layout_matrix = layout_matrix)
```

Les variables `Relative.compactness`, `Overall.height`, `Surface.area` et `Roof.area` semblent être plutôt portées par le premier axe principal (en positif pour les deux premières, négatif pour les deux autres).

Le second axe porte principalement la variable `Wall.area`, et le troisième la variable `Glazing.area`.

Finalement, les deux premiers axes ont plutôt trait à la forme du bâtiment (surface au sol pour le premier et surface murée pour le second), tandis que le troisième axe correspond à la surface vitrée.

Ainsi, l'énergie dépensée dépend d'abord de la forme du bâtiment, et ensuite de la surface vitrée.

Nous pouvons également observer les graphes des individus. Nous représentons les différentes classes énergétiques par couleur.


```{r, fig.dim=c(7,7)}
gg1 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali",
           habillage="Energy.efficiency", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8))
gg2 = plot(res.acp, choix="ind", axes = c(2,3), invisible="quali",
           habillage="Energy.efficiency", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8))
gg3 = plot(res.acp, choix="ind", axes = c(1,3), invisible="quali",
           habillage="Energy.efficiency", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8))
grid.arrange(gg1,gg2,gg3,layout_matrix = layout_matrix)
```

On peut voir sur le premier et le troisième graphique que l'axe 1 marque une claire séparation entre les classes A, B, C et les classes D, E, F, G.

Les maisons dont la consommation énergétique la plus faible possèdent des coordonnées négatives pour la première composante. Ces maisons sont celles qui ont une compacité relative plus faible (plus basses et avec une surface au sol plus élevée), comme on peut le voir sur les graphiques suivants :

```{r, fig.dim=c(7,7)}
gg1 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali",
           habillage="Relative.compactness", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8))
gg2 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali",
           habillage="Surface.area", label = "none", new.plot = FALSE) +
  theme(text = element_text(size=8))
gg3 = plot(res.acp, choix="ind", axes = c(1,2), invisible="quali",
           habillage="Overall.height", label = "none") +
  theme(text = element_text(size=8))
grid.arrange(gg1,gg2,gg3,layout_matrix = layout_matrix)
```

Ainsi, les maisons plus étalées sur le sol possèdent les meilleures performances énergétiques.


## Clustering de variables
### Analyse visuelle

```{r}
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = "#0c4c8a") +
 theme_minimal()
ggplot(data) +
 aes(x = Glazing.area, y = Energy) +
 geom_point(size = 1L, colour = "#0c4c8a") +
 theme_minimal()
```

Visuellement, c'est selon la compacité relative et la surface vitrée que le distingue le mieux des groupes.
Selon la compacité relative, on constate principalement deux groupes. On peut également voir 12 groupes mais ceux-ci sont moins évidents.
Selon la surface vitrée, on distingue principalement 4 groupes.

### Clustering hiérarchique
Après cette analyse visuelle, nous allons utiliser des méthodes de clustering pour confirmer ou infirmer nos observations. Commençons par le clustering hiérarchique.

```{r}
hc = hclust(dist(data[c(1,2,3,4,5,7)]), method = "ward.D2")
plot(hc)
abline(h=3400,col="red")
abline(h=1300,col="red")
abline(h=880,col="red")
abline(h=200,col="red")
plot(sort(hc$height, decreasing = TRUE)[1:20])
abline(v=1.5,col="red")
abline(v=3.5,col="red")
abline(v=4.5,col="red")
abline(v=11.5,col="red")
```
Sur le dendogramme, deux classes apparaissent clairement. On peut aussi distinguer 4,5 ou 12 classes.
Sur le graphique de la variance inter-classe, on observe un saut important au passage à 2 classes. On retrouve également les résultats que l'on a obtenu avec le dendogramme en observant des sauts aux passages à 4, 5 et 12 classes.

Ces premiers outils semblent confirmer les nombres de classes qui semblent pertinents : 2, 4 et 12.

On réalise donc dans un premier temps un découpage en 2, 4 et 12 classes selon le clustering hiérarchique. On compare ces résultats avec nos observations selon plusieurs variables explicatives.

```{r}
class2 = cutree(hc, k = 2)
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
class4 = cutree(hc, k = 4)
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
class12 = cutree(hc, k = 12)
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
```

Visuellement selon la compacité relative, le découpage en 2 groupes et celui en 12 groupes semblent très pertinents. Celui en 4 groupes ne semble pas s'expliquer par la compacité relative.

```{r}
class2 = cutree(hc, k = 2)
ggplot(data) +
 aes(x = Glazing.area, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
class4 = cutree(hc, k = 4)
ggplot(data) +
 aes(x = Glazing.area, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
class12 = cutree(hc, k = 12)
ggplot(data) +
 aes(x = Glazing.area, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
```

Selon la surface vitrée, seul le découpage en 2 classes semble pertinent. On aurait pu s'attendre à un découpage en 4 classes pertinents sur ce graphique mais ce n'est pas le cas.

```{r}
class2 = cutree(hc, k = 2)
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
class4 = cutree(hc, k = 4)
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
class12 = cutree(hc, k = 12)
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
```

Finalement, le découpage en 4 classes semble pertinent selon la surface des murs.

### k-means

On utilise à présent un autre outil : k-means. Comparons les résultats avec ceux du clustering hiérarchique.

```{r}
# k-means à 2 classes
kmres2 = kmeans(data[,c(1:5,7)], centers = 2)
kmclus2 = kmres2$cluster

pairs(data[,quanti], col = kmclus2)

ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = kmclus2) +
 theme_minimal()

# clustering hierarchique à 2 classes
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class2) +
 theme_minimal()
```

Pour le découpage à deux classes, les deux méthodes fournissent exactement les mêmes résultats.

```{r}
# k-means à 4 classes
kmres4 = kmeans(data[,c(1:5,7)], centers = 4)
kmclus4 = kmres4$cluster

pairs(data[,quanti], col = kmclus4)

ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = kmclus4) +
 theme_minimal()

# clustering hierarchique à 4 classes
ggplot(data) +
 aes(x = Wall.area, y = Energy) +
 geom_point(size = 1L, colour = class4) +
 theme_minimal()
```

Après plusieurs exécutions, k-means ne donne presque jamais le même résultat que le clustering hiérarchiques. Alors que le clustering hiérarchiques semble créer des classes pertinentes selon la surface des murs, le k-means réalise souvent un découpage moins pertinent. En effet, le découpage issu de k-means consiste souvent à séparer en deux les données, puis à séparer en trois un des deux groupes obtenus de façon assez arbitraire. Le découpage en 4 classes avec k-means est donc peu pertinent.


```{r}
# k-means à 12 classes
kmres12 = kmeans(data[,c(1:5,7)], centers = 12)
kmclus12 = kmres12$cluster

pairs(data[,quanti], col = kmclus12)

ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = kmclus12) +
 theme_minimal()

# clustering hierarchique à 12 classes
ggplot(data) +
 aes(x = Relative.compactness, y = Energy) +
 geom_point(size = 1L, colour = class12) +
 theme_minimal()
```

Selon les exécutions, k-means donne ici des résultats assez proches du clustering hiérarchique.

### Visualisation des classes sur les axes de l'ACP

On utilise ici les classes obtenues par clustering hiérarchiques car celles-ci semblaient plus naturelles visuellement.

```{r}
data$class2 = as.factor(class2)
data$class4 = as.factor(class4)
data$class12 = as.factor(class12)
res.acp <- PCA(data,scale.unit=T,quali.sup=c(6,8,10,11,12,13),quanti.sup=9,ncp=8, graph=F)
```


```{r}
plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="class2")
plot(res.acp, choix="ind", axes = c(2,3), invisible="quali", habillage="class2")
plot(res.acp, choix="ind", axes = c(1,3), invisible="quali", habillage="class2")
```

On voit ici que les données sont bien découpées en 2 classes selon le premier axe. Cela donne une bonne confiance en le découpage en 2 classes.

```{r}
plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="class4")
plot(res.acp, choix="ind", axes = c(2,3), invisible="quali", habillage="class4")
plot(res.acp, choix="ind", axes = c(1,3), invisible="quali", habillage="class4")
```

Le découpage en 4 classes se fait selon les axes 1 et 2, même si il est moins évident que celui en 2 classes. (notamment sur les classes 3 et 4 ci-dessus).

```{r}
plot(res.acp, choix="ind", axes = c(1,2), invisible="quali", habillage="class12")
plot(res.acp, choix="ind", axes = c(2,3), invisible="quali", habillage="class12")
plot(res.acp, choix="ind", axes = c(1,3), invisible="quali", habillage="class12")
```

Ici, on peut avoir la même observation que pour le découpage en 4 classes : le découpage est moins net que celui en 2 classes et se fait selon les axes 1 et 2.


# Modèles linéaires

## Modèle fonction des variables quantitatives

Nous étudierons dans un premier temps des modèles linéaires expliquant la variable quantitative `Energy` en fonction des variables *quantitatives* uniquement. Nous écarterons cependant la variable `Roof.area`, car nous avons vu qu'elle était combinaison linéaire des variables `Wall.area` et `Surface.area`. La conserver rendrait notre modèle singulier.

### Modèle avec interactions

Nous essayons un premier modèle contenant les variables explicatives et leurs interactions.

```{r}
model_quanti_complet = lm(Energy ~ (. - Roof.area)^2, data = data[,quanti])
r.sq = summary(model_quanti_complet)$r.squared ; paste("R² =", r.sq)
data$fitted_quanti_complet = model_quanti_complet$fitted.values
ggplot(data) + 
  aes(x = fitted_quanti_complet, y = Energy) +
  geom_point(size = 1L) + geom_smooth(method = "lm", formula = "y~x") +
  labs(title = "Regression linéaire de `Energy` en fonction des variables quantitatives",
       x = "Valeurs ajustées") +
  theme_minimal() 
```

Le modèle obtenu semble déjà bien passer au sein des données : on trouve un $R^2$ de 0.8952.

Cependant, ce modèle conserve beaucoup de variables, on peut donc se demander si elles sont toutes pertinentes. Nous allons donc essayer ne n'en conserver que certaines.

### Selection de variables par critère BIC

Nous allons réaliser dans un premier temps une sélection de variables par critère BIC.

```{r}
modselect_bic_back = stepAIC(model_quanti_complet,trace=FALSE,direction=c("backward"),k=log(nrow(data)),)
paste("Energy ~", paste(dimnames(modselect_bic_back$qr$qr)[[2]][-1], collapse=" + "))
```

Le modèle selectionné conserve nos 5 des variables quantitatives, mais supprime certaines de de leur interactions. Afin de s'assurer que l'on peut simplifier notre modèle, on réalise un test de sous-modèle entre le modèle complet et le modèle selectionné.

```{r}
anova(modselect_bic_back, model_quanti_complet)
r.sq = summary(modselect_bic_back)$r.squared ; paste("R² =", r.sq)
```

On obtient une p-valeur de 0.2864. On ne rejette donc pas notre modèle selectionné au seuil de 5 \%.
Ainsi, notre modèle possède un $R^2$ de 0.8943, ce qui est à peine plus faible que ce que nous avions avec toutes nos variables.

### Selection de variable par regression regularisée

On peut également tenter de sélectionner nos variables par régression régularisée.

***Problème sur régression généralisée : tau est nul, voir avec Cathy***

#### Ridge

```{r}
# centrage et réduction des données
eng=scale(data["Energy"],center=T,scale=T)
f = as.formula(paste("Energy ~ (", paste(dimnames(data[,c(1,2,3,5,7)])[[2]], collapse=" + "), ")^2"))
expli=scale(model.matrix(f,data)[,-1],center=T,scale=T)

# création du tableau de tau
tau_seq <- seq(0, 0.002, by = 0.000001)

# regression ridge
fitridge <- glmnet(x = expli, y = eng, family = "gaussian", alpha = 0, lambda = tau_seq, type.measure=c("mse"), intercept = T)

# récupération du tau minimum par validation croisée
ridge_cv = cv.glmnet(x = expli, y = eng, family = "gaussian", alpha = 0, lambda = tau_seq, type.measure=c("mse"), intercept = F)
tau_min_ridge = ridge_cv$lambda.min
print(tau_min_ridge)

# affichage des estimations de tau
dfridge=data.frame(tau = rep(fitridge$lambda,ncol(expli)), theta=as.vector(t(fitridge$beta)),variable=rep(colnames(expli),each=length(fitridge$lambda)))
ggplot(dfridge,aes(x=tau,y=theta,col=variable)) +
  geom_line() +
  geom_vline(xintercept = tau_min_ridge, linetype = "dotted", color = "red") +
  theme(legend.position="right")
```

```{r, echo=FALSE}
# illustration de la meilleure valeur de tau
df2=data.frame(tau=ridge_cv$lambda,MSE=ridge_cv$cvm,cvup=ridge_cv$cvup,cvlo=ridge_cv$cvlo)
ggplot(df2)+
  geom_line(aes(x=tau,y=MSE))+
  geom_vline(xintercept = tau_min_ridge,col="red",linetype="dotted")+
  geom_line(aes(x=tau,y=cvup),col="blue",linetype="dotted")+
  geom_line(aes(x=tau,y=cvlo),col="blue",linetype="dotted")+
  ylim(c(0.115,0.155))
```


#### Lasso

```{r}
# regression lasso
fitlasso <- glmnet(x = expli, y = eng, family = "gaussian", alpha = 1, lambda = tau_seq, type.measure=c("mse"), intercept = F)

# récupération du tau minimum par validation croisée
lasso_cv = cv.glmnet(x = expli, y = eng, family = "gaussian", alpha = 1, lambda = tau_seq, type.measure=c("mse"), intercept = F)
tau_min_lasso = lasso_cv$lambda.min
print(tau_min_lasso)

# affichage des estimations de tau
dflasso=data.frame(tau = rep(fitlasso$lambda,ncol(expli)), theta=as.vector(t(fitlasso$beta)),variable=rep(colnames(expli),each=length(fitlasso$lambda)))
ggplot(dflasso,aes(x=tau,y=theta,col=variable)) +
  geom_line() +
  geom_vline(xintercept = tau_min_lasso, linetype = "dotted", color = "red") +
  theme(legend.position="right")
```

```{r, echo=FALSE}
# illustration de la meilleure valeur de tau
df3=data.frame(tau=lasso_cv$lambda,MSE=lasso_cv$cvm,cvup=lasso_cv$cvup,cvlo=lasso_cv$cvlo)
ggplot(df3)+
  geom_line(aes(x=tau,y=MSE))+
  geom_vline(xintercept = tau_min_lasso,col="red",linetype="dotted")+
  geom_line(aes(x=tau,y=cvup),col="blue",linetype="dotted")+
  geom_line(aes(x=tau,y=cvlo),col="blue",linetype="dotted")+
  ylim(c(0.115,0.155))
```


## Model depending on all variables

```{r}
model_complet = lm(Energy ~ (. - Roof.area)^2, data = data[,c(1:9)])
summary(model_complet)
data$fitted_complet = model_complet$fitted.values
ggplot(data) +
 aes(x = fitted_complet, y = Energy) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")

ggplot(data) +
 aes(x = fitted_complet, y = Energy, col = Glazing.area.distr) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")

ggplot(data) +
 aes(x = fitted_complet, y = Energy, col = orientation) +
 geom_point(size = 1L) +
 theme_minimal() + geom_smooth(method = "lm")
```

```{r}
model_reduit1 = lm(Energy ~ . - Roof.area - orientation, data = data[,c(1:9)])
anova(model_complet, model_reduit1)
summary(model_reduit1)
```

```{r}
selectf = regsubsets(Energy ~ (. - Roof.area)^2, data = data[,c(1:9)],nbest=1,nvmax=10,method="forward")
plot(selectf,scale="bic",main="Forward BIC")
plot(selectf,scale="Cp",main="Forward Cp")
plot(selectf,scale="adjr2",main="Forward adjusted R²")

selectb = regsubsets(Energy ~ (. - Roof.area)^2, data = data[,c(1:9)],nbest=1,nvmax=10,method="backward")
plot(selectb,scale="bic",main="Backward BIC")
plot(selectb,scale="Cp",main="Backward Cp")
plot(selectb,scale="adjr2",main="Backward adjusted R²")
```

```{r}
# model_reduit2
# anova()
```

# Modèle linéaire généralisée

### Mise en forme de la data Frame
```{r}
# Modéle linéaire généralisée
# Définition de Energy.efficiencyBIs
new_data <- data[,c(-11,-12,-13,-14,-15)]
data.mlg = data.frame(new_data, Energy.efficiency.bis = rep(0, nrow(new_data)))
data.mlg$Energy.efficiency.bis[which(data.mlg$Energy.efficiency == "A" | data.mlg$Energy.efficiency == "B")] = "1"
data.mlg$Energy.efficiency.bis[which(data.mlg$Energy.efficiency !="A" & data.mlg$Energy.efficiency !="B" )] = "0"
data.mlg$Energy.efficiency.bis = as.factor(data.mlg$Energy.efficiency.bis)
data.mlg<-data.mlg[,c(-4,-9,-10)]
```

### Statistique descriptive 
```{r}
#Statistique Descriptive
boxplot(Relative.compactness~ Energy.efficiency.bis,data=data.mlg)
boxplot(Surface.area~ Energy.efficiency.bis,data=data.mlg)
boxplot(Wall.area~ Energy.efficiency.bis,data=data.mlg)
boxplot(Overall.height~ Energy.efficiency.bis,data=data.mlg)
boxplot(Glazing.area~ Energy.efficiency.bis,data=data.mlg)
mosaicplot(table(data.mlg[,c("Energy.efficiency.bis","orientation")]))
```
L'analyse descriptive du modèle linéaire généralisé  par rapport à la variable 
Energy.efficiency.bis nous permet de noter les points suivant :
    * Les individus qui ont une meilleure Energy.efficiency.bis ont une Relative compactness faible.
    * Les individus qui ont une meilleure Energy.efficiency.bis ont une Surface.area plus grande.
    * Les individus qui ont une meilleure Energy.efficiency.bis ont des surface de Wall.area faible.
    * Les batiments ayant une overall height faible ont une meilleur Energy.efficiency.bis
    
## Modèle linéaire généralisé additif
Puisque, les variables Surface.area, Wall.area et la Roof.area sont liées, nous allons l'enlever du jeu de données.
En outre, l'analyse statistique nous a permis d'identifier que toutes les variables avaient des effets sur l'Energy.efficiency.bis
donc nous allons considérer le modèle additif
### Ajustement du modèle
```{r}
# Ajustement du modèle linéaire généralisé additif
mlg_rg <- glm(Energy.efficiency.bis~.,data=data.mlg,family=binomial(link=logit))
summary(mlg_rg)
```
### Calcul du pseudo R2
```{r}
#Calcul de pseudo R2 de mlg_rg
pseudoR2 = 1 - ( mlg_rg$deviance/mlg_rg$null.deviance)
print("Pseudo R2 ")
print(pseudoR2)
```
Le Pseudo R2 trouvé est de 0.712, alors on peut modéliser ce problème par un MLG.
### Recherche de sous modèle
```{r}
print("############################  AIC  #############################")
mlg.BIC <- bestglm(data.mlg, family = binomial, IC = "BIC")
mlg.BIC$BestModel
print('')
print("############################  BIC  #############################")
mlg.AIC <- bestglm(data.mlg, family = binomial, IC = "AIC")
mlg.AIC$BestModel
```
###Choix du sous modéle.
#### Comparaison du modèle complet avec le modèle AIC


```{r}
#
mlg_rg_best_aic <- glm(Energy.efficiency.bis~Relative.compactness + Overall.height+Glazing.area,family=binomial(link=logit),data=data.mlg)
anova(mlg_rg_best_aic,mlg_rg,test="Chisq")
```

La pvaleur obtenue étant de 0.003229  donc on rejette le modéle AIC au risque de 5%. 

#### Comparaison du modèle complet avec le modèle BIC
```{r}

# On note que le sous modèle bic est un sous modèle du modèle AIC
#### Comparaison du modèle AIC  avec le sous modèle BIC
mlg_rg_best_bic <- glm(Energy.efficiency.bis~Relative.compactness + Glazing.area + 
    Overall.height + Glazing.area.distr,family=binomial(link=logit),data=data.mlg)
summary(mlg_rg_best_bic)
anova(mlg_rg_best_bic,mlg_rg,test="Chisq")
```
La pvaleur obtenue étant de 0.5543 on retient le modèle BIC au risque 5%

## Modèle avec intéraction
Regardons si le modèle avec intéraction définit mieux le problème de regression.
```{r}
#Ajustement du modèle complet avec intéraction 
mlg_rg_inter <- glm(Energy.efficiency.bis~.^2,data=data.mlg,family=binomial(link="logit"))
summary(mlg_rg_inter)
```

### Calcul du pseudo R2
```{r}
#Calcul de pseudo R2
pseudoR2 = 1 - ( mlg_rg_inter$deviance/mlg_rg_inter$null.deviance)
print("Pseudo R2 ")
print(pseudoR2)
```
Le pseudo R2 obtenu est de 0.7796646 (contre  0.712583 pour le modèle additif).

### Recherche de sous modèle
```{r}
modelbestinter = step(mlg_rg_inter,trace = FALSE)
summary(modelbestinter)
```
### Comparaison du modèle complet avec le sous modèle trouvé par la méthode AIC
```{r}

mlg_inter_best_aic <- glm(Energy.efficiency.bis ~ Relative.compactness + Surface.area + 
    Wall.area + Overall.height + orientation + Glazing.area + 
    Glazing.area.distr + Relative.compactness:Glazing.area + 
    Surface.area:Wall.area + Surface.area:orientation + Surface.area:Glazing.area.distr + 
    Wall.area:orientation + Wall.area:Glazing.area + Overall.height:orientation,family=binomial(link=logit),data=data.mlg)
summary(mlg_inter_best_aic)
anova(mlg_inter_best_aic,mlg_rg_inter,test="Chisq")
```

La pvaleur étant de 0.9577 on ne rejette donc pas H0
ON conserve le sous  modèle AIC
## Choix du meilleur sous modèle
Comparaison du modèle AIC sans intéraction avec le modèle AIC avec intéraction 
Dans ce cas précis les modèle sans intéraction est un sous modèle de celui avec intéraction donc
on peut réaliser un test de sous modèle
```{r}
 
anova(mlg_rg_best_aic,mlg_inter_best_aic,test="Chisq")
```

La pvaleur étant de 0.006016 on rejette H0
Donc on conserve mlg_inter_best_aic.

## Regression polytomique pour la variable Energy.efficiency
###  Mise en forme du jeu de données utilisées
Dans la mise en forme du jeu de données, la variable Energie et Roof.Area ont été supprimées. En raison du fait que,
d'une part les variables Surface.area, Wall.area et la Roof.area sont liées, et d'aute part la variable de sortie 
ici considérée est Energy.efficiency.
```{r}

data.mlg.p<-new_data[,c(-4,-9)]
```
### Statistique descriptive 
```{r}
#Statistique Descriptive
boxplot(Relative.compactness~ Energy.efficiency,data=data.mlg.p)
boxplot(Surface.area~ Energy.efficiency,data=data.mlg.p)
boxplot(Wall.area~ Energy.efficiency,data=data.mlg.p)
boxplot(Overall.height~ Energy.efficiency,data=data.mlg.p)
boxplot(Glazing.area~ Energy.efficiency,data=data.mlg.p)
mosaicplot(table(data.mlg.p[,c("Energy.efficiency","orientation")]))
``` 
L'analyse des figures obtenues nous permet de noter que :
  * Les classes d'energies A,B,C ont une faible relative compactness par rapport aux classes D,E,F,G
  * Les classes d'energies A,B,C ont une grande Surface.area par rapport aux classes D,E,F,G
  * Les classes d'energies B,D,E,F ont en moyenne la même surface de Wall.area, mais pas la même distribution
    La classe A a une faible surface de Wall.area et la classe G en a une grande
  * Les classes d'energies A,B,C ont une faible Overall.height par rapport aux classes D,E,F,G

## Modèle linéaire généralisé polytomique additif
L'analyse statistique nous a permis d'identifier que toutes les variables avaient des effets sur l'Energy.efficiency
donc nous allons considérer le modèle additif.
Nous allons considérer les niveaux comme ordonnées pour notre analyse.
```{r}
# transformation en variable ordinale
data.mlg.p$Energy.efficiency = factor(data.mlg.p$Energy.efficiency, order = TRUE, levels = c("A", "B", 
    "C", "D","E","F","G"))
```

### Ajustement du modèle.
```{r}
modelord <- vglm(Energy.efficiency ~ ., data = data.mlg.p, family = acat())
```